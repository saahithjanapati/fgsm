{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca049c7d-98c5-4deb-91f7-b0fb44d620b9",
   "metadata": {},
   "source": [
    "# Code to train an MNIST Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f997ee7-f5e2-468d-86e2-3abdbfe011b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchvision in /home/jax4zk/.local/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in /home/jax4zk/.local/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.5.1 (from torchvision)\n",
      "  Obtaining dependency information for torch==2.5.1 from https://files.pythonhosted.org/packages/d1/35/e8b2daf02ce933e4518e6f5682c72fd0ed66c15910ea1fb4168f442b71c4/torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jax4zk/.local/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->torchvision)\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==9.1.0.70 from https://files.pythonhosted.org/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.3.1.170)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->torchvision)\n",
      "  Obtaining dependency information for nvidia-nccl-cu12==2.21.5 from https://files.pythonhosted.org/packages/df/99/12cd266d6233f47d00daf3a72739872bdc10267d0383508b0b9c84a18bb6/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jax4zk/.local/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n",
      "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2, torchfrtrace and torchrun are installed in '/home/jax4zk/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lm-eval 0.4.7 requires zstandard, which is not installed.\n",
      "xformers 0.0.27.post2 requires torch==2.4.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cudnn-cu12 nvidia-nccl-cu12 torch\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60747653-2e11-4ea0-af2a-a1c4c7528990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c48b2b-0c85-409e-8f54-f78ea10b4c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8737fa-ee18-4439-b305-3093cb9de16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data', train=True, transform = transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfad523-84b4-4042-928c-3dbe213afa67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
    "val_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b2734c-0ba6-4cf6-a66d-babd5cdb0c84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "xtrain, ytrain = next(iter(train_loader))\n",
    "print(xtrain.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb4359-9639-4de2-8ccc-cdb5cf59ed54",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b5c651-5506-45b1-8106-f6bc089d33d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = torch.softmax(x, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123cb28f-5bc7-4107-b45a-55bd4e814972",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bddb1ae-b2e7-4679-99e5-2f36352e7393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MNISTClassifier()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 2, gamma=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7d6665d-e427-4fee-822e-e90165e9566c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_num_correct(outputs, labels):\n",
    "    # outputs.shape: (b,10)\n",
    "    # labels.shape: (b)\n",
    "    max_output_vals, max_output_indices = outputs.max(dim=-1)\n",
    "    correct = torch.where(max_output_indices == labels, 1, 0)\n",
    "    \n",
    "    num_correct = torch.sum(correct, dim=-1)\n",
    "    total = correct.size(0)\n",
    "    return num_correct, total\n",
    "\n",
    "\n",
    "def run_training_loop(model, optimizer, train_loader, val_loader, scheduler, num_epochs=10, print_every=200):\n",
    "    device = next(model.parameters()).device # device that model is stored on\n",
    "    training_log = {\n",
    "        'training_loss': [],\n",
    "        'training_acc': [],\n",
    "        'validation_loss': [],\n",
    "        'validation_acc': []\n",
    "    }\n",
    "    \n",
    "    model.train()\n",
    "    num_iter = 0\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        for iter_idx, (xb,yb) in enumerate(train_loader):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            xb = xb.view(-1, 784)\n",
    "            out = model(xb) # b, 10\n",
    "            loss = F.cross_entropy(out, yb)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            num_correct, total = calculate_num_correct(out, yb)\n",
    "            \n",
    "            training_log['training_loss'].append((num_iter, loss.item()))\n",
    "            training_log['training_acc'].append((num_iter, num_correct / total))\n",
    "            \n",
    "            if num_iter % print_every == 0:\n",
    "                print(f'Epoch {i}, iter: {num_iter}: training loss: {training_log[\"training_loss\"][-1][1]}, training acc: {training_log[\"training_acc\"][-1][1]}')\n",
    "            \n",
    "            num_iter += 1\n",
    "        \n",
    "        \n",
    "        total_num_correct = 0\n",
    "        total_val_samples = 0\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # run evals\n",
    "        for iter_idx, (xb, yb) in enumerate(val_loader):\n",
    "            \n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            xb = xb.view(-1, 784)\n",
    "            out = model(xb)\n",
    "            loss = F.cross_entropy(out, yb)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "            \n",
    "            num_correct, total = calculate_num_correct(out, yb)\n",
    "            \n",
    "            total_num_correct += num_correct\n",
    "            total_val_samples += total\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            num_batches += 1\n",
    "\n",
    "            \n",
    "            \n",
    "        training_log['validation_loss'].append((num_iter, loss.item()))\n",
    "        training_log['validation_acc'].append((num_iter, num_correct / total))\n",
    "        \n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {i}, iter: {num_iter}: validation loss: {training_log[\"validation_loss\"][-1][1]}, validation acc: {training_log[\"validation_acc\"][-1][1]}')\n",
    "\n",
    "    \n",
    "    return training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1900fb66-97fb-462f-ba3c-5419770f2389",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter: 0: training loss: 2.303898811340332, training acc: 0.0625\n",
      "Epoch 0, iter: 200: training loss: 1.7404704093933105, training acc: 0.71875\n",
      "Epoch 0, iter: 400: training loss: 1.6941438913345337, training acc: 0.765625\n",
      "Epoch 0, iter: 600: training loss: 1.7248358726501465, training acc: 0.71875\n",
      "Epoch 0, iter: 800: training loss: 1.5516202449798584, training acc: 0.90625\n",
      "Epoch 0, iter: 1095: validation loss: 1.5478267669677734, validation acc: 0.9375\n",
      "Epoch 1, iter: 1200: training loss: 1.6116087436676025, training acc: 0.859375\n",
      "Epoch 1, iter: 1400: training loss: 1.5865415334701538, training acc: 0.875\n",
      "Epoch 1, iter: 1600: training loss: 1.6707532405853271, training acc: 0.796875\n",
      "Epoch 1, iter: 1800: training loss: 1.5696589946746826, training acc: 0.890625\n",
      "Epoch 1, iter: 2000: training loss: 1.5519883632659912, training acc: 0.90625\n",
      "Epoch 1, iter: 2190: validation loss: 1.4611504077911377, validation acc: 1.0\n",
      "Epoch 2, iter: 2200: training loss: 1.5532480478286743, training acc: 0.90625\n",
      "Epoch 2, iter: 2400: training loss: 1.5795748233795166, training acc: 0.890625\n",
      "Epoch 2, iter: 2600: training loss: 1.566576361656189, training acc: 0.890625\n",
      "Epoch 2, iter: 2800: training loss: 1.585994005203247, training acc: 0.875\n",
      "Epoch 2, iter: 3000: training loss: 1.56540846824646, training acc: 0.890625\n",
      "Epoch 2, iter: 3285: validation loss: 1.4763121604919434, validation acc: 1.0\n",
      "Epoch 3, iter: 3400: training loss: 1.5549769401550293, training acc: 0.90625\n",
      "Epoch 3, iter: 3600: training loss: 1.5115981101989746, training acc: 0.953125\n",
      "Epoch 3, iter: 3800: training loss: 1.5200591087341309, training acc: 0.9375\n",
      "Epoch 3, iter: 4000: training loss: 1.5750049352645874, training acc: 0.890625\n",
      "Epoch 3, iter: 4200: training loss: 1.5861504077911377, training acc: 0.875\n",
      "Epoch 3, iter: 4380: validation loss: 1.4615378379821777, validation acc: 1.0\n",
      "Epoch 4, iter: 4400: training loss: 1.5514731407165527, training acc: 0.90625\n",
      "Epoch 4, iter: 4600: training loss: 1.6348587274551392, training acc: 0.828125\n",
      "Epoch 4, iter: 4800: training loss: 1.5548943281173706, training acc: 0.90625\n",
      "Epoch 4, iter: 5000: training loss: 1.616349220275879, training acc: 0.84375\n",
      "Epoch 4, iter: 5200: training loss: 1.5855250358581543, training acc: 0.875\n",
      "Epoch 4, iter: 5475: validation loss: 1.5236504077911377, validation acc: 0.9375\n",
      "Epoch 5, iter: 5600: training loss: 1.5146384239196777, training acc: 0.953125\n",
      "Epoch 5, iter: 5800: training loss: 1.6701499223709106, training acc: 0.796875\n",
      "Epoch 5, iter: 6000: training loss: 1.4927077293395996, training acc: 0.96875\n",
      "Epoch 5, iter: 6200: training loss: 1.554106593132019, training acc: 0.90625\n",
      "Epoch 5, iter: 6400: training loss: 1.5701007843017578, training acc: 0.890625\n",
      "Epoch 5, iter: 6570: validation loss: 1.4611504077911377, validation acc: 1.0\n",
      "Epoch 6, iter: 6600: training loss: 1.4767820835113525, training acc: 0.984375\n",
      "Epoch 6, iter: 6800: training loss: 1.5080196857452393, training acc: 0.953125\n",
      "Epoch 6, iter: 7000: training loss: 1.5392746925354004, training acc: 0.921875\n",
      "Epoch 6, iter: 7200: training loss: 1.5080254077911377, training acc: 0.953125\n",
      "Epoch 6, iter: 7400: training loss: 1.553116798400879, training acc: 0.90625\n",
      "Epoch 6, iter: 7665: validation loss: 1.4611504077911377, validation acc: 1.0\n",
      "Epoch 7, iter: 7800: training loss: 1.4910633563995361, training acc: 0.96875\n",
      "Epoch 7, iter: 8000: training loss: 1.4997962713241577, training acc: 0.96875\n",
      "Epoch 7, iter: 8200: training loss: 1.5434908866882324, training acc: 0.921875\n",
      "Epoch 7, iter: 8400: training loss: 1.555896520614624, training acc: 0.90625\n",
      "Epoch 7, iter: 8600: training loss: 1.5117231607437134, training acc: 0.953125\n",
      "Epoch 7, iter: 8760: validation loss: 1.4611504077911377, validation acc: 1.0\n",
      "Epoch 8, iter: 8800: training loss: 1.539280891418457, training acc: 0.921875\n",
      "Epoch 8, iter: 9000: training loss: 1.494840383529663, training acc: 0.96875\n",
      "Epoch 8, iter: 9200: training loss: 1.5080251693725586, training acc: 0.953125\n",
      "Epoch 8, iter: 9400: training loss: 1.53914475440979, training acc: 0.921875\n",
      "Epoch 8, iter: 9600: training loss: 1.523780345916748, training acc: 0.9375\n",
      "Epoch 8, iter: 9855: validation loss: 1.4611504077911377, validation acc: 1.0\n",
      "Epoch 9, iter: 10000: training loss: 1.4789352416992188, training acc: 0.984375\n",
      "Epoch 9, iter: 10200: training loss: 1.600848913192749, training acc: 0.859375\n",
      "Epoch 9, iter: 10400: training loss: 1.5705509185791016, training acc: 0.890625\n",
      "Epoch 9, iter: 10600: training loss: 1.548377513885498, training acc: 0.90625\n",
      "Epoch 9, iter: 10950: validation loss: 1.5236504077911377, validation acc: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_loss': [(0, 2.303898811340332),\n",
       "  (1, 2.301663398742676),\n",
       "  (2, 2.300722599029541),\n",
       "  (3, 2.298607349395752),\n",
       "  (4, 2.2957191467285156),\n",
       "  (5, 2.296870231628418),\n",
       "  (6, 2.2909915447235107),\n",
       "  (7, 2.28743839263916),\n",
       "  (8, 2.257431745529175),\n",
       "  (9, 2.2733426094055176),\n",
       "  (10, 2.275371789932251),\n",
       "  (11, 2.188725471496582),\n",
       "  (12, 2.2323808670043945),\n",
       "  (13, 2.1879100799560547),\n",
       "  (14, 2.1379215717315674),\n",
       "  (15, 2.1807310581207275),\n",
       "  (16, 2.111475944519043),\n",
       "  (17, 2.104257345199585),\n",
       "  (18, 2.1866612434387207),\n",
       "  (19, 2.045283079147339),\n",
       "  (20, 2.095831871032715),\n",
       "  (21, 2.1798534393310547),\n",
       "  (22, 2.0370898246765137),\n",
       "  (23, 2.0884451866149902),\n",
       "  (24, 2.1116597652435303),\n",
       "  (25, 2.0978055000305176),\n",
       "  (26, 1.9934695959091187),\n",
       "  (27, 2.149066209793091),\n",
       "  (28, 2.087299346923828),\n",
       "  (29, 2.084160566329956),\n",
       "  (30, 2.0706589221954346),\n",
       "  (31, 2.060039520263672),\n",
       "  (32, 2.18245005607605),\n",
       "  (33, 2.103854179382324),\n",
       "  (34, 1.9840469360351562),\n",
       "  (35, 2.124175786972046),\n",
       "  (36, 2.0356643199920654),\n",
       "  (37, 1.9795787334442139),\n",
       "  (38, 2.0107169151306152),\n",
       "  (39, 1.917067050933838),\n",
       "  (40, 1.9325069189071655),\n",
       "  (41, 1.9377802610397339),\n",
       "  (42, 1.999494194984436),\n",
       "  (43, 2.016258955001831),\n",
       "  (44, 1.991700530052185),\n",
       "  (45, 2.0312328338623047),\n",
       "  (46, 2.0040972232818604),\n",
       "  (47, 1.9205516576766968),\n",
       "  (48, 1.9688382148742676),\n",
       "  (49, 2.048978567123413),\n",
       "  (50, 1.9095244407653809),\n",
       "  (51, 1.9675220251083374),\n",
       "  (52, 2.052381753921509),\n",
       "  (53, 1.8926905393600464),\n",
       "  (54, 2.008355140686035),\n",
       "  (55, 1.968050241470337),\n",
       "  (56, 1.9912793636322021),\n",
       "  (57, 2.027757167816162),\n",
       "  (58, 2.0953471660614014),\n",
       "  (59, 1.9688162803649902),\n",
       "  (60, 1.882071614265442),\n",
       "  (61, 1.9175643920898438),\n",
       "  (62, 1.9001752138137817),\n",
       "  (63, 1.8299652338027954),\n",
       "  (64, 1.9092882871627808),\n",
       "  (65, 1.7981799840927124),\n",
       "  (66, 1.9742871522903442),\n",
       "  (67, 1.8340643644332886),\n",
       "  (68, 1.8945807218551636),\n",
       "  (69, 1.752773642539978),\n",
       "  (70, 1.8560404777526855),\n",
       "  (71, 1.84636652469635),\n",
       "  (72, 1.8457505702972412),\n",
       "  (73, 1.8426011800765991),\n",
       "  (74, 1.919615387916565),\n",
       "  (75, 1.8779500722885132),\n",
       "  (76, 1.8249866962432861),\n",
       "  (77, 1.867680549621582),\n",
       "  (78, 1.926895260810852),\n",
       "  (79, 1.8544280529022217),\n",
       "  (80, 1.8319884538650513),\n",
       "  (81, 1.7194797992706299),\n",
       "  (82, 1.92702317237854),\n",
       "  (83, 1.875807285308838),\n",
       "  (84, 1.7901188135147095),\n",
       "  (85, 1.7666540145874023),\n",
       "  (86, 1.875943899154663),\n",
       "  (87, 1.809002161026001),\n",
       "  (88, 1.801391839981079),\n",
       "  (89, 1.7473092079162598),\n",
       "  (90, 1.8120386600494385),\n",
       "  (91, 1.7965179681777954),\n",
       "  (92, 1.792365312576294),\n",
       "  (93, 1.779018521308899),\n",
       "  (94, 1.8953343629837036),\n",
       "  (95, 1.8261075019836426),\n",
       "  (96, 1.8501545190811157),\n",
       "  (97, 1.804492712020874),\n",
       "  (98, 1.7493972778320312),\n",
       "  (99, 1.7435975074768066),\n",
       "  (100, 1.7502055168151855),\n",
       "  (101, 1.7191615104675293),\n",
       "  (102, 1.8289600610733032),\n",
       "  (103, 1.732607126235962),\n",
       "  (104, 1.7523112297058105),\n",
       "  (105, 1.7265188694000244),\n",
       "  (106, 1.7470543384552002),\n",
       "  (107, 1.802963376045227),\n",
       "  (108, 1.7982574701309204),\n",
       "  (109, 1.852769374847412),\n",
       "  (110, 1.7338708639144897),\n",
       "  (111, 1.7936067581176758),\n",
       "  (112, 1.7715762853622437),\n",
       "  (113, 1.8650881052017212),\n",
       "  (114, 1.7520108222961426),\n",
       "  (115, 1.7437130212783813),\n",
       "  (116, 1.7724179029464722),\n",
       "  (117, 1.8026347160339355),\n",
       "  (118, 1.6661298274993896),\n",
       "  (119, 1.7758058309555054),\n",
       "  (120, 1.78481924533844),\n",
       "  (121, 1.7887920141220093),\n",
       "  (122, 1.680579423904419),\n",
       "  (123, 1.822119116783142),\n",
       "  (124, 1.7045128345489502),\n",
       "  (125, 1.808309555053711),\n",
       "  (126, 1.9235591888427734),\n",
       "  (127, 1.7991405725479126),\n",
       "  (128, 1.8242688179016113),\n",
       "  (129, 1.8121503591537476),\n",
       "  (130, 1.694161057472229),\n",
       "  (131, 1.7594797611236572),\n",
       "  (132, 1.811546802520752),\n",
       "  (133, 1.8573106527328491),\n",
       "  (134, 1.708297848701477),\n",
       "  (135, 1.8154852390289307),\n",
       "  (136, 1.7401840686798096),\n",
       "  (137, 1.8357675075531006),\n",
       "  (138, 1.7973307371139526),\n",
       "  (139, 1.799373745918274),\n",
       "  (140, 1.8462852239608765),\n",
       "  (141, 1.6790506839752197),\n",
       "  (142, 1.821329116821289),\n",
       "  (143, 1.6818159818649292),\n",
       "  (144, 1.7164945602416992),\n",
       "  (145, 1.730332851409912),\n",
       "  (146, 1.7881492376327515),\n",
       "  (147, 1.6392242908477783),\n",
       "  (148, 1.713402509689331),\n",
       "  (149, 1.8405669927597046),\n",
       "  (150, 1.7791380882263184),\n",
       "  (151, 1.8189356327056885),\n",
       "  (152, 1.8382283449172974),\n",
       "  (153, 1.806333303451538),\n",
       "  (154, 1.7914050817489624),\n",
       "  (155, 1.8021752834320068),\n",
       "  (156, 1.6861798763275146),\n",
       "  (157, 1.742194652557373),\n",
       "  (158, 1.8713979721069336),\n",
       "  (159, 1.7402044534683228),\n",
       "  (160, 1.7431626319885254),\n",
       "  (161, 1.7269068956375122),\n",
       "  (162, 1.6430788040161133),\n",
       "  (163, 1.6786261796951294),\n",
       "  (164, 1.7157456874847412),\n",
       "  (165, 1.7733858823776245),\n",
       "  (166, 1.7590631246566772),\n",
       "  (167, 1.7428618669509888),\n",
       "  (168, 1.7485467195510864),\n",
       "  (169, 1.75516939163208),\n",
       "  (170, 1.7693636417388916),\n",
       "  (171, 1.8251558542251587),\n",
       "  (172, 1.7253804206848145),\n",
       "  (173, 1.7773361206054688),\n",
       "  (174, 1.738810658454895),\n",
       "  (175, 1.8941230773925781),\n",
       "  (176, 1.7478673458099365),\n",
       "  (177, 1.7750244140625),\n",
       "  (178, 1.711987018585205),\n",
       "  (179, 1.7607449293136597),\n",
       "  (180, 1.7756483554840088),\n",
       "  (181, 1.7234201431274414),\n",
       "  (182, 1.856297492980957),\n",
       "  (183, 1.7008261680603027),\n",
       "  (184, 1.6872634887695312),\n",
       "  (185, 1.752769112586975),\n",
       "  (186, 1.674161434173584),\n",
       "  (187, 1.7108322381973267),\n",
       "  (188, 1.7225301265716553),\n",
       "  (189, 1.7445902824401855),\n",
       "  (190, 1.7430405616760254),\n",
       "  (191, 1.731553316116333),\n",
       "  (192, 1.8165321350097656),\n",
       "  (193, 1.8112049102783203),\n",
       "  (194, 1.7248858213424683),\n",
       "  (195, 1.7836811542510986),\n",
       "  (196, 1.8335716724395752),\n",
       "  (197, 1.9115972518920898),\n",
       "  (198, 1.7697525024414062),\n",
       "  (199, 1.7034276723861694),\n",
       "  (200, 1.7404704093933105),\n",
       "  (201, 1.758007526397705),\n",
       "  (202, 1.7155799865722656),\n",
       "  (203, 1.8018109798431396),\n",
       "  (204, 1.7572987079620361),\n",
       "  (205, 1.6579055786132812),\n",
       "  (206, 1.813799500465393),\n",
       "  (207, 1.8316792249679565),\n",
       "  (208, 1.8212097883224487),\n",
       "  (209, 1.71310555934906),\n",
       "  (210, 1.7262389659881592),\n",
       "  (211, 1.7172819375991821),\n",
       "  (212, 1.762105941772461),\n",
       "  (213, 1.639101266860962),\n",
       "  (214, 1.6730011701583862),\n",
       "  (215, 1.6436594724655151),\n",
       "  (216, 1.6714158058166504),\n",
       "  (217, 1.70042085647583),\n",
       "  (218, 1.6258350610733032),\n",
       "  (219, 1.7773096561431885),\n",
       "  (220, 1.729078769683838),\n",
       "  (221, 1.698290228843689),\n",
       "  (222, 1.727967381477356),\n",
       "  (223, 1.6363061666488647),\n",
       "  (224, 1.6746798753738403),\n",
       "  (225, 1.6167880296707153),\n",
       "  (226, 1.728882074356079),\n",
       "  (227, 1.6558386087417603),\n",
       "  (228, 1.7808445692062378),\n",
       "  (229, 1.7415955066680908),\n",
       "  (230, 1.707931637763977),\n",
       "  (231, 1.6736702919006348),\n",
       "  (232, 1.8147696256637573),\n",
       "  (233, 1.7127058506011963),\n",
       "  (234, 1.750028371810913),\n",
       "  (235, 1.6938879489898682),\n",
       "  (236, 1.8974394798278809),\n",
       "  (237, 1.7468138933181763),\n",
       "  (238, 1.6865142583847046),\n",
       "  (239, 1.8053847551345825),\n",
       "  (240, 1.7025299072265625),\n",
       "  (241, 1.7397173643112183),\n",
       "  (242, 1.7314820289611816),\n",
       "  (243, 1.7432847023010254),\n",
       "  (244, 1.7659707069396973),\n",
       "  (245, 1.7617195844650269),\n",
       "  (246, 1.6880311965942383),\n",
       "  (247, 1.7606463432312012),\n",
       "  (248, 1.825502872467041),\n",
       "  (249, 1.7977509498596191),\n",
       "  (250, 1.7387497425079346),\n",
       "  (251, 1.694691777229309),\n",
       "  (252, 1.7354899644851685),\n",
       "  (253, 1.7033323049545288),\n",
       "  (254, 1.6465623378753662),\n",
       "  (255, 1.726947546005249),\n",
       "  (256, 1.7031241655349731),\n",
       "  (257, 1.78451669216156),\n",
       "  (258, 1.7464983463287354),\n",
       "  (259, 1.6916085481643677),\n",
       "  (260, 1.6661512851715088),\n",
       "  (261, 1.660356044769287),\n",
       "  (262, 1.6187736988067627),\n",
       "  (263, 1.668459177017212),\n",
       "  (264, 1.6345999240875244),\n",
       "  (265, 1.735451340675354),\n",
       "  (266, 1.714077115058899),\n",
       "  (267, 1.7042758464813232),\n",
       "  (268, 1.818051815032959),\n",
       "  (269, 1.7687771320343018),\n",
       "  (270, 1.6763246059417725),\n",
       "  (271, 1.7216777801513672),\n",
       "  (272, 1.6489238739013672),\n",
       "  (273, 1.706822156906128),\n",
       "  (274, 1.752805471420288),\n",
       "  (275, 1.7442694902420044),\n",
       "  (276, 1.7616915702819824),\n",
       "  (277, 1.6384397745132446),\n",
       "  (278, 1.6796351671218872),\n",
       "  (279, 1.649284839630127),\n",
       "  (280, 1.8014005422592163),\n",
       "  (281, 1.7201344966888428),\n",
       "  (282, 1.6863367557525635),\n",
       "  (283, 1.678820252418518),\n",
       "  (284, 1.709376335144043),\n",
       "  (285, 1.6660575866699219),\n",
       "  (286, 1.7054963111877441),\n",
       "  (287, 1.6531425714492798),\n",
       "  (288, 1.6371650695800781),\n",
       "  (289, 1.797347903251648),\n",
       "  (290, 1.6909875869750977),\n",
       "  (291, 1.7319773435592651),\n",
       "  (292, 1.7133079767227173),\n",
       "  (293, 1.7488722801208496),\n",
       "  (294, 1.6604681015014648),\n",
       "  (295, 1.6815063953399658),\n",
       "  (296, 1.7880420684814453),\n",
       "  (297, 1.7458363771438599),\n",
       "  (298, 1.7580890655517578),\n",
       "  (299, 1.8256244659423828),\n",
       "  (300, 1.858221411705017),\n",
       "  (301, 1.6844948530197144),\n",
       "  (302, 1.7535293102264404),\n",
       "  (303, 1.7335268259048462),\n",
       "  (304, 1.7814921140670776),\n",
       "  (305, 1.7392545938491821),\n",
       "  (306, 1.7112088203430176),\n",
       "  (307, 1.7466955184936523),\n",
       "  (308, 1.7154232263565063),\n",
       "  (309, 1.686298131942749),\n",
       "  (310, 1.7299914360046387),\n",
       "  (311, 1.6621458530426025),\n",
       "  (312, 1.6494395732879639),\n",
       "  (313, 1.762868881225586),\n",
       "  (314, 1.7120623588562012),\n",
       "  (315, 1.781808853149414),\n",
       "  (316, 1.7380127906799316),\n",
       "  (317, 1.7692222595214844),\n",
       "  (318, 1.685743808746338),\n",
       "  (319, 1.6640135049819946),\n",
       "  (320, 1.6535375118255615),\n",
       "  (321, 1.7141658067703247),\n",
       "  (322, 1.7618731260299683),\n",
       "  (323, 1.6441175937652588),\n",
       "  (324, 1.7004693746566772),\n",
       "  (325, 1.60698401927948),\n",
       "  (326, 1.7338265180587769),\n",
       "  (327, 1.786278486251831),\n",
       "  (328, 1.728355884552002),\n",
       "  (329, 1.721541166305542),\n",
       "  (330, 1.6580342054367065),\n",
       "  (331, 1.6459990739822388),\n",
       "  (332, 1.7420310974121094),\n",
       "  (333, 1.6685996055603027),\n",
       "  (334, 1.6897974014282227),\n",
       "  (335, 1.6920586824417114),\n",
       "  (336, 1.6388804912567139),\n",
       "  (337, 1.661786437034607),\n",
       "  (338, 1.6992688179016113),\n",
       "  (339, 1.7437925338745117),\n",
       "  (340, 1.7738449573516846),\n",
       "  (341, 1.726012110710144),\n",
       "  (342, 1.7946834564208984),\n",
       "  (343, 1.6151456832885742),\n",
       "  (344, 1.7667059898376465),\n",
       "  (345, 1.6614879369735718),\n",
       "  (346, 1.6541872024536133),\n",
       "  (347, 1.7498979568481445),\n",
       "  (348, 1.727468729019165),\n",
       "  (349, 1.6530343294143677),\n",
       "  (350, 1.679775595664978),\n",
       "  (351, 1.6519582271575928),\n",
       "  (352, 1.6504684686660767),\n",
       "  (353, 1.5806325674057007),\n",
       "  (354, 1.7368422746658325),\n",
       "  (355, 1.7246973514556885),\n",
       "  (356, 1.6987823247909546),\n",
       "  (357, 1.7458993196487427),\n",
       "  (358, 1.6117318868637085),\n",
       "  (359, 1.6544374227523804),\n",
       "  (360, 1.6995073556900024),\n",
       "  (361, 1.6978212594985962),\n",
       "  (362, 1.6950448751449585),\n",
       "  (363, 1.6361415386199951),\n",
       "  (364, 1.7387200593948364),\n",
       "  (365, 1.60332453250885),\n",
       "  (366, 1.6256431341171265),\n",
       "  (367, 1.7514417171478271),\n",
       "  (368, 1.7013875246047974),\n",
       "  (369, 1.6889768838882446),\n",
       "  (370, 1.7203441858291626),\n",
       "  (371, 1.637256145477295),\n",
       "  (372, 1.69048273563385),\n",
       "  (373, 1.686011552810669),\n",
       "  (374, 1.7204922437667847),\n",
       "  (375, 1.675965666770935),\n",
       "  (376, 1.749730110168457),\n",
       "  (377, 1.653996467590332),\n",
       "  (378, 1.7439806461334229),\n",
       "  (379, 1.7078421115875244),\n",
       "  (380, 1.5982455015182495),\n",
       "  (381, 1.6416511535644531),\n",
       "  (382, 1.618240237236023),\n",
       "  (383, 1.7394566535949707),\n",
       "  (384, 1.6863698959350586),\n",
       "  (385, 1.654747486114502),\n",
       "  (386, 1.7076787948608398),\n",
       "  (387, 1.6774497032165527),\n",
       "  (388, 1.6194926500320435),\n",
       "  (389, 1.6227644681930542),\n",
       "  (390, 1.681537389755249),\n",
       "  (391, 1.703532338142395),\n",
       "  (392, 1.6833469867706299),\n",
       "  (393, 1.717787265777588),\n",
       "  (394, 1.6897586584091187),\n",
       "  (395, 1.7650377750396729),\n",
       "  (396, 1.6033446788787842),\n",
       "  (397, 1.687225103378296),\n",
       "  (398, 1.7535498142242432),\n",
       "  (399, 1.7007743120193481),\n",
       "  (400, 1.6941438913345337),\n",
       "  (401, 1.7100043296813965),\n",
       "  (402, 1.7625263929367065),\n",
       "  (403, 1.7094643115997314),\n",
       "  (404, 1.668705701828003),\n",
       "  (405, 1.629319667816162),\n",
       "  (406, 1.7571755647659302),\n",
       "  (407, 1.6412701606750488),\n",
       "  (408, 1.6808371543884277),\n",
       "  (409, 1.7223089933395386),\n",
       "  (410, 1.6879581212997437),\n",
       "  (411, 1.7231478691101074),\n",
       "  (412, 1.6541796922683716),\n",
       "  (413, 1.6769102811813354),\n",
       "  (414, 1.6418286561965942),\n",
       "  (415, 1.684154748916626),\n",
       "  (416, 1.7015280723571777),\n",
       "  (417, 1.6318773031234741),\n",
       "  (418, 1.699745774269104),\n",
       "  (419, 1.628494143486023),\n",
       "  (420, 1.6480515003204346),\n",
       "  (421, 1.7218983173370361),\n",
       "  (422, 1.7294474840164185),\n",
       "  (423, 1.6754943132400513),\n",
       "  (424, 1.728905439376831),\n",
       "  (425, 1.7417957782745361),\n",
       "  (426, 1.6804945468902588),\n",
       "  (427, 1.6648237705230713),\n",
       "  (428, 1.6262788772583008),\n",
       "  (429, 1.6185214519500732),\n",
       "  (430, 1.6139262914657593),\n",
       "  (431, 1.7261207103729248),\n",
       "  (432, 1.6682039499282837),\n",
       "  (433, 1.5653306245803833),\n",
       "  (434, 1.6205381155014038),\n",
       "  (435, 1.7653241157531738),\n",
       "  (436, 1.7200936079025269),\n",
       "  (437, 1.611876368522644),\n",
       "  (438, 1.6793544292449951),\n",
       "  (439, 1.6908907890319824),\n",
       "  (440, 1.683208703994751),\n",
       "  (441, 1.6012829542160034),\n",
       "  (442, 1.6134339570999146),\n",
       "  (443, 1.6154506206512451),\n",
       "  (444, 1.6461055278778076),\n",
       "  (445, 1.700878381729126),\n",
       "  (446, 1.6754212379455566),\n",
       "  (447, 1.6758533716201782),\n",
       "  (448, 1.7060015201568604),\n",
       "  (449, 1.676114559173584),\n",
       "  (450, 1.6496082544326782),\n",
       "  (451, 1.7196691036224365),\n",
       "  (452, 1.6563518047332764),\n",
       "  (453, 1.6637935638427734),\n",
       "  (454, 1.6739435195922852),\n",
       "  (455, 1.7276945114135742),\n",
       "  (456, 1.6718494892120361),\n",
       "  (457, 1.6777124404907227),\n",
       "  (458, 1.7313841581344604),\n",
       "  (459, 1.7014650106430054),\n",
       "  (460, 1.6940871477127075),\n",
       "  (461, 1.6830532550811768),\n",
       "  (462, 1.7125885486602783),\n",
       "  (463, 1.731931209564209),\n",
       "  (464, 1.7481980323791504),\n",
       "  (465, 1.674381136894226),\n",
       "  (466, 1.785175085067749),\n",
       "  (467, 1.737775444984436),\n",
       "  (468, 1.77924382686615),\n",
       "  (469, 1.6916042566299438),\n",
       "  (470, 1.743591547012329),\n",
       "  (471, 1.750617265701294),\n",
       "  (472, 1.6775962114334106),\n",
       "  (473, 1.6243419647216797),\n",
       "  (474, 1.617983341217041),\n",
       "  (475, 1.7318300008773804),\n",
       "  (476, 1.652717113494873),\n",
       "  (477, 1.6910842657089233),\n",
       "  (478, 1.602578043937683),\n",
       "  (479, 1.7831820249557495),\n",
       "  (480, 1.638124942779541),\n",
       "  (481, 1.664270043373108),\n",
       "  (482, 1.6797723770141602),\n",
       "  (483, 1.6572781801223755),\n",
       "  (484, 1.663279414176941),\n",
       "  (485, 1.644565463066101),\n",
       "  (486, 1.733020544052124),\n",
       "  (487, 1.671588659286499),\n",
       "  (488, 1.6822125911712646),\n",
       "  (489, 1.664050579071045),\n",
       "  (490, 1.613109827041626),\n",
       "  (491, 1.652904987335205),\n",
       "  (492, 1.6381109952926636),\n",
       "  (493, 1.6560438871383667),\n",
       "  (494, 1.6028765439987183),\n",
       "  (495, 1.7133376598358154),\n",
       "  (496, 1.6575744152069092),\n",
       "  (497, 1.7220234870910645),\n",
       "  (498, 1.7287440299987793),\n",
       "  (499, 1.6132291555404663),\n",
       "  (500, 1.74089515209198),\n",
       "  (501, 1.7912781238555908),\n",
       "  (502, 1.6406364440917969),\n",
       "  (503, 1.713004469871521),\n",
       "  (504, 1.6862579584121704),\n",
       "  (505, 1.7251447439193726),\n",
       "  (506, 1.728522539138794),\n",
       "  (507, 1.6640026569366455),\n",
       "  (508, 1.6428197622299194),\n",
       "  (509, 1.677122950553894),\n",
       "  (510, 1.6517709493637085),\n",
       "  (511, 1.6355665922164917),\n",
       "  (512, 1.665402889251709),\n",
       "  (513, 1.7525726556777954),\n",
       "  (514, 1.6320914030075073),\n",
       "  (515, 1.667138695716858),\n",
       "  (516, 1.6446000337600708),\n",
       "  (517, 1.6441707611083984),\n",
       "  (518, 1.6327118873596191),\n",
       "  (519, 1.7021796703338623),\n",
       "  (520, 1.7502743005752563),\n",
       "  (521, 1.6490494012832642),\n",
       "  (522, 1.707533836364746),\n",
       "  (523, 1.755329966545105),\n",
       "  (524, 1.6441006660461426),\n",
       "  (525, 1.5973293781280518),\n",
       "  (526, 1.5930569171905518),\n",
       "  (527, 1.6292915344238281),\n",
       "  (528, 1.6424204111099243),\n",
       "  (529, 1.7391811609268188),\n",
       "  (530, 1.7223680019378662),\n",
       "  (531, 1.6258115768432617),\n",
       "  (532, 1.6586533784866333),\n",
       "  (533, 1.5935927629470825),\n",
       "  (534, 1.7482593059539795),\n",
       "  (535, 1.6636326313018799),\n",
       "  (536, 1.6641936302185059),\n",
       "  (537, 1.7122857570648193),\n",
       "  (538, 1.6332957744598389),\n",
       "  (539, 1.7550041675567627),\n",
       "  (540, 1.7500596046447754),\n",
       "  (541, 1.704352855682373),\n",
       "  (542, 1.7028968334197998),\n",
       "  (543, 1.7604626417160034),\n",
       "  (544, 1.6700912714004517),\n",
       "  (545, 1.7193766832351685),\n",
       "  (546, 1.6501153707504272),\n",
       "  (547, 1.6138325929641724),\n",
       "  (548, 1.5859507322311401),\n",
       "  (549, 1.5725072622299194),\n",
       "  (550, 1.5512956380844116),\n",
       "  (551, 1.5878840684890747),\n",
       "  (552, 1.6185532808303833),\n",
       "  (553, 1.6087722778320312),\n",
       "  (554, 1.6114550828933716),\n",
       "  (555, 1.5793943405151367),\n",
       "  (556, 1.683000087738037),\n",
       "  (557, 1.7735553979873657),\n",
       "  (558, 1.6286319494247437),\n",
       "  (559, 1.6019251346588135),\n",
       "  (560, 1.6620968580245972),\n",
       "  (561, 1.5901801586151123),\n",
       "  (562, 1.6807012557983398),\n",
       "  (563, 1.5845777988433838),\n",
       "  (564, 1.678978443145752),\n",
       "  (565, 1.55674147605896),\n",
       "  (566, 1.5706030130386353),\n",
       "  (567, 1.569433331489563),\n",
       "  (568, 1.597176194190979),\n",
       "  (569, 1.5811989307403564),\n",
       "  (570, 1.5963696241378784),\n",
       "  (571, 1.6079003810882568),\n",
       "  (572, 1.540865421295166),\n",
       "  (573, 1.5820305347442627),\n",
       "  (574, 1.538570761680603),\n",
       "  (575, 1.6236900091171265),\n",
       "  (576, 1.5509380102157593),\n",
       "  (577, 1.6724879741668701),\n",
       "  (578, 1.560969352722168),\n",
       "  (579, 1.6073592901229858),\n",
       "  (580, 1.6111729145050049),\n",
       "  (581, 1.6016712188720703),\n",
       "  (582, 1.6256027221679688),\n",
       "  (583, 1.6413040161132812),\n",
       "  (584, 1.5458331108093262),\n",
       "  (585, 1.609419584274292),\n",
       "  (586, 1.606741189956665),\n",
       "  (587, 1.602298617362976),\n",
       "  (588, 1.6567392349243164),\n",
       "  (589, 1.618028163909912),\n",
       "  (590, 1.6815273761749268),\n",
       "  (591, 1.6858763694763184),\n",
       "  (592, 1.5527799129486084),\n",
       "  (593, 1.5895065069198608),\n",
       "  (594, 1.5571304559707642),\n",
       "  (595, 1.621713399887085),\n",
       "  (596, 1.6659791469573975),\n",
       "  (597, 1.6681711673736572),\n",
       "  (598, 1.6834945678710938),\n",
       "  (599, 1.663215160369873),\n",
       "  (600, 1.7248358726501465),\n",
       "  (601, 1.67520010471344),\n",
       "  (602, 1.7164788246154785),\n",
       "  (603, 1.620132565498352),\n",
       "  (604, 1.6390976905822754),\n",
       "  (605, 1.6498993635177612),\n",
       "  (606, 1.617701768875122),\n",
       "  (607, 1.6693603992462158),\n",
       "  (608, 1.6587934494018555),\n",
       "  (609, 1.6601089239120483),\n",
       "  (610, 1.586452841758728),\n",
       "  (611, 1.6005098819732666),\n",
       "  (612, 1.6124088764190674),\n",
       "  (613, 1.5959341526031494),\n",
       "  (614, 1.6796410083770752),\n",
       "  (615, 1.5528521537780762),\n",
       "  (616, 1.6676713228225708),\n",
       "  (617, 1.6739646196365356),\n",
       "  (618, 1.6029040813446045),\n",
       "  (619, 1.6059542894363403),\n",
       "  (620, 1.571523666381836),\n",
       "  (621, 1.6767232418060303),\n",
       "  (622, 1.5424872636795044),\n",
       "  (623, 1.6617610454559326),\n",
       "  (624, 1.5876809358596802),\n",
       "  (625, 1.584994912147522),\n",
       "  (626, 1.6253619194030762),\n",
       "  (627, 1.6050982475280762),\n",
       "  (628, 1.608402967453003),\n",
       "  (629, 1.5942527055740356),\n",
       "  (630, 1.5783286094665527),\n",
       "  (631, 1.645522952079773),\n",
       "  (632, 1.582769513130188),\n",
       "  (633, 1.5516254901885986),\n",
       "  (634, 1.6183490753173828),\n",
       "  (635, 1.6705322265625),\n",
       "  (636, 1.5983717441558838),\n",
       "  (637, 1.6534266471862793),\n",
       "  (638, 1.5613757371902466),\n",
       "  (639, 1.6750218868255615),\n",
       "  (640, 1.5608781576156616),\n",
       "  (641, 1.6407972574234009),\n",
       "  (642, 1.6183280944824219),\n",
       "  (643, 1.6525421142578125),\n",
       "  (644, 1.5999352931976318),\n",
       "  (645, 1.6547880172729492),\n",
       "  (646, 1.5361864566802979),\n",
       "  (647, 1.725593090057373),\n",
       "  (648, 1.562394618988037),\n",
       "  (649, 1.5629754066467285),\n",
       "  (650, 1.663905143737793),\n",
       "  (651, 1.6179442405700684),\n",
       "  (652, 1.6737130880355835),\n",
       "  (653, 1.5545566082000732),\n",
       "  (654, 1.5711932182312012),\n",
       "  (655, 1.6641775369644165),\n",
       "  (656, 1.5151335000991821),\n",
       "  (657, 1.549344539642334),\n",
       "  (658, 1.581702470779419),\n",
       "  (659, 1.633363962173462),\n",
       "  (660, 1.528278112411499),\n",
       "  (661, 1.6351836919784546),\n",
       "  (662, 1.647158145904541),\n",
       "  (663, 1.601447343826294),\n",
       "  (664, 1.6459473371505737),\n",
       "  (665, 1.6439318656921387),\n",
       "  (666, 1.6057814359664917),\n",
       "  (667, 1.6249608993530273),\n",
       "  (668, 1.6750787496566772),\n",
       "  (669, 1.6406447887420654),\n",
       "  (670, 1.656294345855713),\n",
       "  (671, 1.7403020858764648),\n",
       "  (672, 1.5870610475540161),\n",
       "  (673, 1.5706977844238281),\n",
       "  (674, 1.5666253566741943),\n",
       "  (675, 1.5366042852401733),\n",
       "  (676, 1.6001476049423218),\n",
       "  (677, 1.5424762964248657),\n",
       "  (678, 1.6728358268737793),\n",
       "  (679, 1.6695880889892578),\n",
       "  (680, 1.5983996391296387),\n",
       "  (681, 1.6070512533187866),\n",
       "  (682, 1.5325555801391602),\n",
       "  (683, 1.621270775794983),\n",
       "  (684, 1.60531485080719),\n",
       "  (685, 1.6256192922592163),\n",
       "  (686, 1.57270348072052),\n",
       "  (687, 1.556344985961914),\n",
       "  (688, 1.5364751815795898),\n",
       "  (689, 1.5965795516967773),\n",
       "  (690, 1.5732837915420532),\n",
       "  (691, 1.6147714853286743),\n",
       "  (692, 1.611602544784546),\n",
       "  (693, 1.5919073820114136),\n",
       "  (694, 1.5677553415298462),\n",
       "  (695, 1.669431209564209),\n",
       "  (696, 1.5880967378616333),\n",
       "  (697, 1.6155979633331299),\n",
       "  (698, 1.5985064506530762),\n",
       "  (699, 1.6645451784133911),\n",
       "  (700, 1.6481115818023682),\n",
       "  (701, 1.595955491065979),\n",
       "  (702, 1.5709404945373535),\n",
       "  (703, 1.5850340127944946),\n",
       "  (704, 1.5381956100463867),\n",
       "  (705, 1.6464818716049194),\n",
       "  (706, 1.524092435836792),\n",
       "  (707, 1.5142892599105835),\n",
       "  (708, 1.6135809421539307),\n",
       "  (709, 1.5786877870559692),\n",
       "  (710, 1.5970919132232666),\n",
       "  (711, 1.6121469736099243),\n",
       "  (712, 1.602401852607727),\n",
       "  (713, 1.656217098236084),\n",
       "  (714, 1.5739290714263916),\n",
       "  (715, 1.6100232601165771),\n",
       "  (716, 1.5596224069595337),\n",
       "  (717, 1.5730817317962646),\n",
       "  (718, 1.566028356552124),\n",
       "  (719, 1.5857962369918823),\n",
       "  (720, 1.545334815979004),\n",
       "  (721, 1.7390838861465454),\n",
       "  (722, 1.5724360942840576),\n",
       "  (723, 1.5762461423873901),\n",
       "  (724, 1.5812479257583618),\n",
       "  (725, 1.5803571939468384),\n",
       "  (726, 1.5283915996551514),\n",
       "  (727, 1.5919941663742065),\n",
       "  (728, 1.6379162073135376),\n",
       "  (729, 1.6658202409744263),\n",
       "  (730, 1.6275019645690918),\n",
       "  (731, 1.5549981594085693),\n",
       "  (732, 1.6261961460113525),\n",
       "  (733, 1.601931095123291),\n",
       "  (734, 1.5821621417999268),\n",
       "  (735, 1.556091547012329),\n",
       "  (736, 1.538680076599121),\n",
       "  (737, 1.5760047435760498),\n",
       "  (738, 1.6483683586120605),\n",
       "  (739, 1.5891693830490112),\n",
       "  (740, 1.641897201538086),\n",
       "  (741, 1.5293586254119873),\n",
       "  (742, 1.5507092475891113),\n",
       "  (743, 1.6293468475341797),\n",
       "  (744, 1.700423002243042),\n",
       "  (745, 1.6031863689422607),\n",
       "  (746, 1.6066033840179443),\n",
       "  (747, 1.5730574131011963),\n",
       "  (748, 1.5642356872558594),\n",
       "  (749, 1.5695877075195312),\n",
       "  (750, 1.6021324396133423),\n",
       "  (751, 1.5496772527694702),\n",
       "  (752, 1.639246940612793),\n",
       "  (753, 1.6867022514343262),\n",
       "  (754, 1.5653650760650635),\n",
       "  (755, 1.5714092254638672),\n",
       "  (756, 1.6509859561920166),\n",
       "  (757, 1.587357759475708),\n",
       "  (758, 1.5455535650253296),\n",
       "  (759, 1.5916633605957031),\n",
       "  (760, 1.5890326499938965),\n",
       "  (761, 1.50635826587677),\n",
       "  (762, 1.648526906967163),\n",
       "  (763, 1.6340930461883545),\n",
       "  (764, 1.5760109424591064),\n",
       "  (765, 1.586714267730713),\n",
       "  (766, 1.5783629417419434),\n",
       "  (767, 1.5943039655685425),\n",
       "  (768, 1.5990478992462158),\n",
       "  (769, 1.5762488842010498),\n",
       "  (770, 1.6001677513122559),\n",
       "  (771, 1.5866901874542236),\n",
       "  (772, 1.6423300504684448),\n",
       "  (773, 1.5621901750564575),\n",
       "  (774, 1.579894781112671),\n",
       "  (775, 1.5525527000427246),\n",
       "  (776, 1.6736551523208618),\n",
       "  (777, 1.6080337762832642),\n",
       "  (778, 1.6350823640823364),\n",
       "  (779, 1.6344739198684692),\n",
       "  (780, 1.5789889097213745),\n",
       "  (781, 1.6544018983840942),\n",
       "  (782, 1.6053850650787354),\n",
       "  (783, 1.6527965068817139),\n",
       "  (784, 1.7686653137207031),\n",
       "  (785, 1.5878229141235352),\n",
       "  (786, 1.5760047435760498),\n",
       "  (787, 1.610772967338562),\n",
       "  (788, 1.6146246194839478),\n",
       "  (789, 1.5659117698669434),\n",
       "  (790, 1.5455951690673828),\n",
       "  (791, 1.5594338178634644),\n",
       "  (792, 1.5723203420639038),\n",
       "  (793, 1.5821607112884521),\n",
       "  (794, 1.5669893026351929),\n",
       "  (795, 1.5729281902313232),\n",
       "  (796, 1.5385830402374268),\n",
       "  (797, 1.5177829265594482),\n",
       "  (798, 1.6602373123168945),\n",
       "  (799, 1.6790521144866943),\n",
       "  (800, 1.5516202449798584),\n",
       "  (801, 1.497042179107666),\n",
       "  (802, 1.544943928718567),\n",
       "  (803, 1.6030797958374023),\n",
       "  (804, 1.6772571802139282),\n",
       "  (805, 1.5736013650894165),\n",
       "  (806, 1.5498805046081543),\n",
       "  (807, 1.5457093715667725),\n",
       "  (808, 1.588332176208496),\n",
       "  (809, 1.601470708847046),\n",
       "  (810, 1.5748907327651978),\n",
       "  (811, 1.5405700206756592),\n",
       "  (812, 1.5209299325942993),\n",
       "  (813, 1.5300519466400146),\n",
       "  (814, 1.6420133113861084),\n",
       "  (815, 1.6119965314865112),\n",
       "  (816, 1.5672502517700195),\n",
       "  (817, 1.5869007110595703),\n",
       "  (818, 1.587364912033081),\n",
       "  (819, 1.6031455993652344),\n",
       "  (820, 1.5937831401824951),\n",
       "  (821, 1.5880653858184814),\n",
       "  (822, 1.5937364101409912),\n",
       "  (823, 1.6095335483551025),\n",
       "  (824, 1.6484557390213013),\n",
       "  (825, 1.571249008178711),\n",
       "  (826, 1.6311976909637451),\n",
       "  (827, 1.5844687223434448),\n",
       "  (828, 1.5946184396743774),\n",
       "  (829, 1.577817440032959),\n",
       "  (830, 1.5362262725830078),\n",
       "  (831, 1.540286660194397),\n",
       "  (832, 1.6434873342514038),\n",
       "  (833, 1.5462536811828613),\n",
       "  (834, 1.5230540037155151),\n",
       "  (835, 1.5602014064788818),\n",
       "  (836, 1.5583622455596924),\n",
       "  (837, 1.5404633283615112),\n",
       "  (838, 1.5738637447357178),\n",
       "  (839, 1.6572610139846802),\n",
       "  (840, 1.6278226375579834),\n",
       "  (841, 1.6448564529418945),\n",
       "  (842, 1.6343398094177246),\n",
       "  (843, 1.641760230064392),\n",
       "  (844, 1.5796570777893066),\n",
       "  (845, 1.571262240409851),\n",
       "  (846, 1.576326847076416),\n",
       "  (847, 1.577008605003357),\n",
       "  (848, 1.5213677883148193),\n",
       "  (849, 1.5810675621032715),\n",
       "  (850, 1.543247938156128),\n",
       "  (851, 1.547090768814087),\n",
       "  (852, 1.5723521709442139),\n",
       "  (853, 1.61826491355896),\n",
       "  (854, 1.6092875003814697),\n",
       "  (855, 1.6293001174926758),\n",
       "  (856, 1.5695959329605103),\n",
       "  (857, 1.5559520721435547),\n",
       "  (858, 1.5631706714630127),\n",
       "  (859, 1.5511668920516968),\n",
       "  (860, 1.5486849546432495),\n",
       "  (861, 1.5454411506652832),\n",
       "  (862, 1.525156855583191),\n",
       "  (863, 1.5228387117385864),\n",
       "  (864, 1.611405611038208),\n",
       "  (865, 1.6321319341659546),\n",
       "  (866, 1.6581053733825684),\n",
       "  (867, 1.5782428979873657),\n",
       "  (868, 1.5283875465393066),\n",
       "  (869, 1.5475232601165771),\n",
       "  (870, 1.5559911727905273),\n",
       "  (871, 1.5934416055679321),\n",
       "  (872, 1.5965908765792847),\n",
       "  (873, 1.5625715255737305),\n",
       "  (874, 1.5824848413467407),\n",
       "  (875, 1.526925802230835),\n",
       "  (876, 1.560799241065979),\n",
       "  (877, 1.5569099187850952),\n",
       "  (878, 1.6496188640594482),\n",
       "  (879, 1.5369420051574707),\n",
       "  (880, 1.5765424966812134),\n",
       "  (881, 1.6687939167022705),\n",
       "  (882, 1.5389564037322998),\n",
       "  (883, 1.5569710731506348),\n",
       "  (884, 1.5663111209869385),\n",
       "  (885, 1.6037030220031738),\n",
       "  (886, 1.5413799285888672),\n",
       "  (887, 1.6073355674743652),\n",
       "  (888, 1.5536502599716187),\n",
       "  (889, 1.5930185317993164),\n",
       "  (890, 1.5227681398391724),\n",
       "  (891, 1.553555965423584),\n",
       "  (892, 1.6014769077301025),\n",
       "  (893, 1.6315504312515259),\n",
       "  (894, 1.6587916612625122),\n",
       "  (895, 1.5963075160980225),\n",
       "  (896, 1.611269235610962),\n",
       "  (897, 1.607408046722412),\n",
       "  (898, 1.5387628078460693),\n",
       "  (899, 1.6191561222076416),\n",
       "  (900, 1.5854415893554688),\n",
       "  (901, 1.5734195709228516),\n",
       "  (902, 1.6605345010757446),\n",
       "  (903, 1.5883973836898804),\n",
       "  (904, 1.651360034942627),\n",
       "  (905, 1.679581880569458),\n",
       "  (906, 1.5879491567611694),\n",
       "  (907, 1.6127548217773438),\n",
       "  (908, 1.6013678312301636),\n",
       "  (909, 1.6106668710708618),\n",
       "  (910, 1.6199426651000977),\n",
       "  (911, 1.692835807800293),\n",
       "  (912, 1.6056184768676758),\n",
       "  (913, 1.582155704498291),\n",
       "  (914, 1.5430630445480347),\n",
       "  (915, 1.6040570735931396),\n",
       "  (916, 1.5535309314727783),\n",
       "  (917, 1.5554791688919067),\n",
       "  (918, 1.6551995277404785),\n",
       "  (919, 1.6215587854385376),\n",
       "  (920, 1.5762578248977661),\n",
       "  (921, 1.5101664066314697),\n",
       "  (922, 1.5627752542495728),\n",
       "  (923, 1.549398422241211),\n",
       "  (924, 1.5987333059310913),\n",
       "  (925, 1.6824569702148438),\n",
       "  (926, 1.5641262531280518),\n",
       "  (927, 1.6990686655044556),\n",
       "  (928, 1.6639528274536133),\n",
       "  (929, 1.6346591711044312),\n",
       "  (930, 1.551432728767395),\n",
       "  (931, 1.5992753505706787),\n",
       "  (932, 1.5524767637252808),\n",
       "  (933, 1.50071120262146),\n",
       "  (934, 1.646336555480957),\n",
       "  (935, 1.6049492359161377),\n",
       "  (936, 1.5831295251846313),\n",
       "  (937, 1.6735273599624634),\n",
       "  (1095, 1.542720079421997),\n",
       "  (1096, 1.6180827617645264),\n",
       "  (1097, 1.6702364683151245),\n",
       "  (1098, 1.6144853830337524),\n",
       "  (1099, 1.5633628368377686),\n",
       "  (1100, 1.6233596801757812),\n",
       "  (1101, 1.5811759233474731),\n",
       "  (1102, 1.723668098449707),\n",
       "  (1103, 1.6391842365264893),\n",
       "  (1104, 1.631691575050354),\n",
       "  (1105, 1.5354485511779785),\n",
       "  (1106, 1.5657624006271362),\n",
       "  (1107, 1.661246418952942),\n",
       "  (1108, 1.5117133855819702),\n",
       "  (1109, 1.5402085781097412),\n",
       "  (1110, 1.5997413396835327),\n",
       "  (1111, 1.612766981124878),\n",
       "  (1112, 1.5631831884384155),\n",
       "  (1113, 1.6815283298492432),\n",
       "  (1114, 1.6258736848831177),\n",
       "  (1115, 1.614196538925171),\n",
       "  (1116, 1.604588270187378),\n",
       "  (1117, 1.580978274345398),\n",
       "  (1118, 1.594310998916626),\n",
       "  (1119, 1.5457663536071777),\n",
       "  (1120, 1.5800756216049194),\n",
       "  (1121, 1.5935561656951904),\n",
       "  (1122, 1.5556102991104126),\n",
       "  (1123, 1.6225993633270264),\n",
       "  (1124, 1.5270612239837646),\n",
       "  (1125, 1.6173009872436523),\n",
       "  (1126, 1.654455304145813),\n",
       "  (1127, 1.621273159980774),\n",
       "  (1128, 1.6111265420913696),\n",
       "  (1129, 1.6166938543319702),\n",
       "  (1130, 1.6592297554016113),\n",
       "  (1131, 1.6408450603485107),\n",
       "  (1132, 1.6330078840255737),\n",
       "  (1133, 1.6235289573669434),\n",
       "  (1134, 1.535478115081787),\n",
       "  (1135, 1.5814926624298096),\n",
       "  (1136, 1.567171573638916),\n",
       "  (1137, 1.5199549198150635),\n",
       "  (1138, 1.5701191425323486),\n",
       "  (1139, 1.5930593013763428),\n",
       "  (1140, 1.58990478515625),\n",
       "  (1141, 1.5849872827529907),\n",
       "  (1142, 1.59598708152771),\n",
       "  (1143, 1.5992748737335205),\n",
       "  (1144, 1.5828759670257568),\n",
       "  (1145, 1.601204514503479),\n",
       "  (1146, 1.5255374908447266),\n",
       "  (1147, 1.5717430114746094),\n",
       "  (1148, 1.6336013078689575),\n",
       "  (1149, 1.5265355110168457),\n",
       "  (1150, 1.5643064975738525),\n",
       "  (1151, 1.554567575454712),\n",
       "  (1152, 1.5767375230789185),\n",
       "  (1153, 1.6161428689956665),\n",
       "  (1154, 1.5535094738006592),\n",
       "  (1155, 1.576335072517395),\n",
       "  (1156, 1.585648536682129),\n",
       "  ...],\n",
       " 'training_acc': [(0, tensor(0.0625)),\n",
       "  (1, tensor(0.1250)),\n",
       "  (2, tensor(0.2031)),\n",
       "  (3, tensor(0.1719)),\n",
       "  (4, tensor(0.1250)),\n",
       "  (5, tensor(0.1250)),\n",
       "  (6, tensor(0.1719)),\n",
       "  (7, tensor(0.1875)),\n",
       "  (8, tensor(0.2344)),\n",
       "  (9, tensor(0.1562)),\n",
       "  (10, tensor(0.1406)),\n",
       "  (11, tensor(0.3594)),\n",
       "  (12, tensor(0.2812)),\n",
       "  (13, tensor(0.2188)),\n",
       "  (14, tensor(0.3438)),\n",
       "  (15, tensor(0.2188)),\n",
       "  (16, tensor(0.3594)),\n",
       "  (17, tensor(0.4219)),\n",
       "  (18, tensor(0.2656)),\n",
       "  (19, tensor(0.4531)),\n",
       "  (20, tensor(0.3750)),\n",
       "  (21, tensor(0.2812)),\n",
       "  (22, tensor(0.4219)),\n",
       "  (23, tensor(0.3750)),\n",
       "  (24, tensor(0.3125)),\n",
       "  (25, tensor(0.3438)),\n",
       "  (26, tensor(0.4688)),\n",
       "  (27, tensor(0.3125)),\n",
       "  (28, tensor(0.4062)),\n",
       "  (29, tensor(0.3750)),\n",
       "  (30, tensor(0.3750)),\n",
       "  (31, tensor(0.3750)),\n",
       "  (32, tensor(0.2656)),\n",
       "  (33, tensor(0.3281)),\n",
       "  (34, tensor(0.4688)),\n",
       "  (35, tensor(0.3125)),\n",
       "  (36, tensor(0.4375)),\n",
       "  (37, tensor(0.4844)),\n",
       "  (38, tensor(0.4844)),\n",
       "  (39, tensor(0.5781)),\n",
       "  (40, tensor(0.5156)),\n",
       "  (41, tensor(0.5312)),\n",
       "  (42, tensor(0.4531)),\n",
       "  (43, tensor(0.4375)),\n",
       "  (44, tensor(0.4531)),\n",
       "  (45, tensor(0.4375)),\n",
       "  (46, tensor(0.4375)),\n",
       "  (47, tensor(0.5312)),\n",
       "  (48, tensor(0.4844)),\n",
       "  (49, tensor(0.3906)),\n",
       "  (50, tensor(0.5625)),\n",
       "  (51, tensor(0.4844)),\n",
       "  (52, tensor(0.3750)),\n",
       "  (53, tensor(0.5625)),\n",
       "  (54, tensor(0.4219)),\n",
       "  (55, tensor(0.5000)),\n",
       "  (56, tensor(0.5000)),\n",
       "  (57, tensor(0.3906)),\n",
       "  (58, tensor(0.3594)),\n",
       "  (59, tensor(0.5156)),\n",
       "  (60, tensor(0.5938)),\n",
       "  (61, tensor(0.5625)),\n",
       "  (62, tensor(0.5469)),\n",
       "  (63, tensor(0.6719)),\n",
       "  (64, tensor(0.5938)),\n",
       "  (65, tensor(0.7031)),\n",
       "  (66, tensor(0.5000)),\n",
       "  (67, tensor(0.6875)),\n",
       "  (68, tensor(0.5625)),\n",
       "  (69, tensor(0.7031)),\n",
       "  (70, tensor(0.6250)),\n",
       "  (71, tensor(0.5938)),\n",
       "  (72, tensor(0.6250)),\n",
       "  (73, tensor(0.6094)),\n",
       "  (74, tensor(0.5625)),\n",
       "  (75, tensor(0.6094)),\n",
       "  (76, tensor(0.6250)),\n",
       "  (77, tensor(0.5938)),\n",
       "  (78, tensor(0.5312)),\n",
       "  (79, tensor(0.5938)),\n",
       "  (80, tensor(0.6406)),\n",
       "  (81, tensor(0.7344)),\n",
       "  (82, tensor(0.5625)),\n",
       "  (83, tensor(0.5938)),\n",
       "  (84, tensor(0.6719)),\n",
       "  (85, tensor(0.6875)),\n",
       "  (86, tensor(0.5781)),\n",
       "  (87, tensor(0.6562)),\n",
       "  (88, tensor(0.6719)),\n",
       "  (89, tensor(0.7188)),\n",
       "  (90, tensor(0.6406)),\n",
       "  (91, tensor(0.6719)),\n",
       "  (92, tensor(0.7031)),\n",
       "  (93, tensor(0.6719)),\n",
       "  (94, tensor(0.5625)),\n",
       "  (95, tensor(0.6406)),\n",
       "  (96, tensor(0.6250)),\n",
       "  (97, tensor(0.6719)),\n",
       "  (98, tensor(0.7344)),\n",
       "  (99, tensor(0.7188)),\n",
       "  (100, tensor(0.7031)),\n",
       "  (101, tensor(0.7188)),\n",
       "  (102, tensor(0.6250)),\n",
       "  (103, tensor(0.7344)),\n",
       "  (104, tensor(0.7031)),\n",
       "  (105, tensor(0.7656)),\n",
       "  (106, tensor(0.7188)),\n",
       "  (107, tensor(0.6719)),\n",
       "  (108, tensor(0.6719)),\n",
       "  (109, tensor(0.5781)),\n",
       "  (110, tensor(0.7344)),\n",
       "  (111, tensor(0.6562)),\n",
       "  (112, tensor(0.6875)),\n",
       "  (113, tensor(0.6094)),\n",
       "  (114, tensor(0.7188)),\n",
       "  (115, tensor(0.7188)),\n",
       "  (116, tensor(0.6719)),\n",
       "  (117, tensor(0.6719)),\n",
       "  (118, tensor(0.8281)),\n",
       "  (119, tensor(0.6719)),\n",
       "  (120, tensor(0.6719)),\n",
       "  (121, tensor(0.6719)),\n",
       "  (122, tensor(0.7969)),\n",
       "  (123, tensor(0.6250)),\n",
       "  (124, tensor(0.7656)),\n",
       "  (125, tensor(0.6562)),\n",
       "  (126, tensor(0.5625)),\n",
       "  (127, tensor(0.6719)),\n",
       "  (128, tensor(0.5938)),\n",
       "  (129, tensor(0.6406)),\n",
       "  (130, tensor(0.7656)),\n",
       "  (131, tensor(0.6719)),\n",
       "  (132, tensor(0.6406)),\n",
       "  (133, tensor(0.5938)),\n",
       "  (134, tensor(0.7500)),\n",
       "  (135, tensor(0.6562)),\n",
       "  (136, tensor(0.7188)),\n",
       "  (137, tensor(0.6250)),\n",
       "  (138, tensor(0.7031)),\n",
       "  (139, tensor(0.6562)),\n",
       "  (140, tensor(0.6094)),\n",
       "  (141, tensor(0.7812)),\n",
       "  (142, tensor(0.6406)),\n",
       "  (143, tensor(0.7969)),\n",
       "  (144, tensor(0.7656)),\n",
       "  (145, tensor(0.7344)),\n",
       "  (146, tensor(0.6719)),\n",
       "  (147, tensor(0.8125)),\n",
       "  (148, tensor(0.7344)),\n",
       "  (149, tensor(0.6250)),\n",
       "  (150, tensor(0.6875)),\n",
       "  (151, tensor(0.6562)),\n",
       "  (152, tensor(0.6250)),\n",
       "  (153, tensor(0.6562)),\n",
       "  (154, tensor(0.6719)),\n",
       "  (155, tensor(0.6562)),\n",
       "  (156, tensor(0.7812)),\n",
       "  (157, tensor(0.7344)),\n",
       "  (158, tensor(0.5938)),\n",
       "  (159, tensor(0.7188)),\n",
       "  (160, tensor(0.7188)),\n",
       "  (161, tensor(0.7500)),\n",
       "  (162, tensor(0.8281)),\n",
       "  (163, tensor(0.7969)),\n",
       "  (164, tensor(0.7656)),\n",
       "  (165, tensor(0.6875)),\n",
       "  (166, tensor(0.7031)),\n",
       "  (167, tensor(0.7188)),\n",
       "  (168, tensor(0.7031)),\n",
       "  (169, tensor(0.7031)),\n",
       "  (170, tensor(0.6875)),\n",
       "  (171, tensor(0.6406)),\n",
       "  (172, tensor(0.7500)),\n",
       "  (173, tensor(0.6875)),\n",
       "  (174, tensor(0.7188)),\n",
       "  (175, tensor(0.5469)),\n",
       "  (176, tensor(0.7188)),\n",
       "  (177, tensor(0.6875)),\n",
       "  (178, tensor(0.7500)),\n",
       "  (179, tensor(0.7031)),\n",
       "  (180, tensor(0.7031)),\n",
       "  (181, tensor(0.7344)),\n",
       "  (182, tensor(0.5938)),\n",
       "  (183, tensor(0.7656)),\n",
       "  (184, tensor(0.7969)),\n",
       "  (185, tensor(0.7188)),\n",
       "  (186, tensor(0.7812)),\n",
       "  (187, tensor(0.7500)),\n",
       "  (188, tensor(0.7344)),\n",
       "  (189, tensor(0.7031)),\n",
       "  (190, tensor(0.7031)),\n",
       "  (191, tensor(0.7344)),\n",
       "  (192, tensor(0.6562)),\n",
       "  (193, tensor(0.6406)),\n",
       "  (194, tensor(0.7500)),\n",
       "  (195, tensor(0.6719)),\n",
       "  (196, tensor(0.6250)),\n",
       "  (197, tensor(0.5469)),\n",
       "  (198, tensor(0.6719)),\n",
       "  (199, tensor(0.7656)),\n",
       "  (200, tensor(0.7188)),\n",
       "  (201, tensor(0.7031)),\n",
       "  (202, tensor(0.7344)),\n",
       "  (203, tensor(0.6562)),\n",
       "  (204, tensor(0.7031)),\n",
       "  (205, tensor(0.8125)),\n",
       "  (206, tensor(0.6406)),\n",
       "  (207, tensor(0.6094)),\n",
       "  (208, tensor(0.6406)),\n",
       "  (209, tensor(0.7656)),\n",
       "  (210, tensor(0.7344)),\n",
       "  (211, tensor(0.7500)),\n",
       "  (212, tensor(0.6875)),\n",
       "  (213, tensor(0.8125)),\n",
       "  (214, tensor(0.7656)),\n",
       "  (215, tensor(0.8125)),\n",
       "  (216, tensor(0.7812)),\n",
       "  (217, tensor(0.7500)),\n",
       "  (218, tensor(0.8438)),\n",
       "  (219, tensor(0.6875)),\n",
       "  (220, tensor(0.7188)),\n",
       "  (221, tensor(0.7500)),\n",
       "  (222, tensor(0.7344)),\n",
       "  (223, tensor(0.8281)),\n",
       "  (224, tensor(0.7812)),\n",
       "  (225, tensor(0.8438)),\n",
       "  (226, tensor(0.7344)),\n",
       "  (227, tensor(0.8281)),\n",
       "  (228, tensor(0.6875)),\n",
       "  (229, tensor(0.7344)),\n",
       "  (230, tensor(0.7500)),\n",
       "  (231, tensor(0.7812)),\n",
       "  (232, tensor(0.6406)),\n",
       "  (233, tensor(0.7500)),\n",
       "  (234, tensor(0.6875)),\n",
       "  (235, tensor(0.7656)),\n",
       "  (236, tensor(0.5625)),\n",
       "  (237, tensor(0.7188)),\n",
       "  (238, tensor(0.7812)),\n",
       "  (239, tensor(0.6406)),\n",
       "  (240, tensor(0.7656)),\n",
       "  (241, tensor(0.7344)),\n",
       "  (242, tensor(0.7344)),\n",
       "  (243, tensor(0.7188)),\n",
       "  (244, tensor(0.7031)),\n",
       "  (245, tensor(0.7031)),\n",
       "  (246, tensor(0.7812)),\n",
       "  (247, tensor(0.6875)),\n",
       "  (248, tensor(0.6250)),\n",
       "  (249, tensor(0.6562)),\n",
       "  (250, tensor(0.7188)),\n",
       "  (251, tensor(0.7656)),\n",
       "  (252, tensor(0.7031)),\n",
       "  (253, tensor(0.7656)),\n",
       "  (254, tensor(0.8125)),\n",
       "  (255, tensor(0.7188)),\n",
       "  (256, tensor(0.7500)),\n",
       "  (257, tensor(0.6875)),\n",
       "  (258, tensor(0.7188)),\n",
       "  (259, tensor(0.7656)),\n",
       "  (260, tensor(0.7969)),\n",
       "  (261, tensor(0.8125)),\n",
       "  (262, tensor(0.8438)),\n",
       "  (263, tensor(0.7812)),\n",
       "  (264, tensor(0.8281)),\n",
       "  (265, tensor(0.7188)),\n",
       "  (266, tensor(0.7500)),\n",
       "  (267, tensor(0.7500)),\n",
       "  (268, tensor(0.6406)),\n",
       "  (269, tensor(0.6875)),\n",
       "  (270, tensor(0.7969)),\n",
       "  (271, tensor(0.7344)),\n",
       "  (272, tensor(0.8125)),\n",
       "  (273, tensor(0.7500)),\n",
       "  (274, tensor(0.7188)),\n",
       "  (275, tensor(0.7188)),\n",
       "  (276, tensor(0.7031)),\n",
       "  (277, tensor(0.8281)),\n",
       "  (278, tensor(0.7812)),\n",
       "  (279, tensor(0.7969)),\n",
       "  (280, tensor(0.6406)),\n",
       "  (281, tensor(0.7344)),\n",
       "  (282, tensor(0.7812)),\n",
       "  (283, tensor(0.7812)),\n",
       "  (284, tensor(0.7500)),\n",
       "  (285, tensor(0.7969)),\n",
       "  (286, tensor(0.7656)),\n",
       "  (287, tensor(0.8125)),\n",
       "  (288, tensor(0.8438)),\n",
       "  (289, tensor(0.6562)),\n",
       "  (290, tensor(0.7656)),\n",
       "  (291, tensor(0.7344)),\n",
       "  (292, tensor(0.7500)),\n",
       "  (293, tensor(0.7188)),\n",
       "  (294, tensor(0.7969)),\n",
       "  (295, tensor(0.7812)),\n",
       "  (296, tensor(0.6719)),\n",
       "  (297, tensor(0.7188)),\n",
       "  (298, tensor(0.7031)),\n",
       "  (299, tensor(0.6250)),\n",
       "  (300, tensor(0.5938)),\n",
       "  (301, tensor(0.7812)),\n",
       "  (302, tensor(0.6875)),\n",
       "  (303, tensor(0.7188)),\n",
       "  (304, tensor(0.6719)),\n",
       "  (305, tensor(0.7188)),\n",
       "  (306, tensor(0.7500)),\n",
       "  (307, tensor(0.7188)),\n",
       "  (308, tensor(0.7344)),\n",
       "  (309, tensor(0.7812)),\n",
       "  (310, tensor(0.7344)),\n",
       "  (311, tensor(0.8125)),\n",
       "  (312, tensor(0.7969)),\n",
       "  (313, tensor(0.7031)),\n",
       "  (314, tensor(0.7500)),\n",
       "  (315, tensor(0.6719)),\n",
       "  (316, tensor(0.7344)),\n",
       "  (317, tensor(0.6719)),\n",
       "  (318, tensor(0.7812)),\n",
       "  (319, tensor(0.7812)),\n",
       "  (320, tensor(0.8125)),\n",
       "  (321, tensor(0.7500)),\n",
       "  (322, tensor(0.6875)),\n",
       "  (323, tensor(0.8281)),\n",
       "  (324, tensor(0.7500)),\n",
       "  (325, tensor(0.8594)),\n",
       "  (326, tensor(0.7188)),\n",
       "  (327, tensor(0.6719)),\n",
       "  (328, tensor(0.7344)),\n",
       "  (329, tensor(0.7188)),\n",
       "  (330, tensor(0.7969)),\n",
       "  (331, tensor(0.7969)),\n",
       "  (332, tensor(0.7188)),\n",
       "  (333, tensor(0.7969)),\n",
       "  (334, tensor(0.7812)),\n",
       "  (335, tensor(0.7656)),\n",
       "  (336, tensor(0.8125)),\n",
       "  (337, tensor(0.7812)),\n",
       "  (338, tensor(0.7500)),\n",
       "  (339, tensor(0.7188)),\n",
       "  (340, tensor(0.6875)),\n",
       "  (341, tensor(0.7344)),\n",
       "  (342, tensor(0.6562)),\n",
       "  (343, tensor(0.8438)),\n",
       "  (344, tensor(0.6875)),\n",
       "  (345, tensor(0.8125)),\n",
       "  (346, tensor(0.8125)),\n",
       "  (347, tensor(0.7188)),\n",
       "  (348, tensor(0.7031)),\n",
       "  (349, tensor(0.7969)),\n",
       "  (350, tensor(0.7656)),\n",
       "  (351, tensor(0.8125)),\n",
       "  (352, tensor(0.8125)),\n",
       "  (353, tensor(0.8750)),\n",
       "  (354, tensor(0.7188)),\n",
       "  (355, tensor(0.7188)),\n",
       "  (356, tensor(0.7500)),\n",
       "  (357, tensor(0.7031)),\n",
       "  (358, tensor(0.8438)),\n",
       "  (359, tensor(0.7969)),\n",
       "  (360, tensor(0.7656)),\n",
       "  (361, tensor(0.7656)),\n",
       "  (362, tensor(0.7500)),\n",
       "  (363, tensor(0.8125)),\n",
       "  (364, tensor(0.7188)),\n",
       "  (365, tensor(0.8594)),\n",
       "  (366, tensor(0.8594)),\n",
       "  (367, tensor(0.7188)),\n",
       "  (368, tensor(0.7656)),\n",
       "  (369, tensor(0.7812)),\n",
       "  (370, tensor(0.7344)),\n",
       "  (371, tensor(0.8281)),\n",
       "  (372, tensor(0.7656)),\n",
       "  (373, tensor(0.7812)),\n",
       "  (374, tensor(0.7188)),\n",
       "  (375, tensor(0.7812)),\n",
       "  (376, tensor(0.6875)),\n",
       "  (377, tensor(0.8125)),\n",
       "  (378, tensor(0.7188)),\n",
       "  (379, tensor(0.7500)),\n",
       "  (380, tensor(0.8594)),\n",
       "  (381, tensor(0.8125)),\n",
       "  (382, tensor(0.8438)),\n",
       "  (383, tensor(0.7188)),\n",
       "  (384, tensor(0.7812)),\n",
       "  (385, tensor(0.7969)),\n",
       "  (386, tensor(0.7500)),\n",
       "  (387, tensor(0.7812)),\n",
       "  (388, tensor(0.8438)),\n",
       "  (389, tensor(0.8281)),\n",
       "  (390, tensor(0.7656)),\n",
       "  (391, tensor(0.7656)),\n",
       "  (392, tensor(0.7969)),\n",
       "  (393, tensor(0.7344)),\n",
       "  (394, tensor(0.7656)),\n",
       "  (395, tensor(0.7031)),\n",
       "  (396, tensor(0.8438)),\n",
       "  (397, tensor(0.7656)),\n",
       "  (398, tensor(0.7188)),\n",
       "  (399, tensor(0.7656)),\n",
       "  (400, tensor(0.7656)),\n",
       "  (401, tensor(0.7500)),\n",
       "  (402, tensor(0.6875)),\n",
       "  (403, tensor(0.7500)),\n",
       "  (404, tensor(0.7969)),\n",
       "  (405, tensor(0.8281)),\n",
       "  (406, tensor(0.7031)),\n",
       "  (407, tensor(0.8281)),\n",
       "  (408, tensor(0.7812)),\n",
       "  (409, tensor(0.7344)),\n",
       "  (410, tensor(0.7812)),\n",
       "  (411, tensor(0.7344)),\n",
       "  (412, tensor(0.7969)),\n",
       "  (413, tensor(0.7812)),\n",
       "  (414, tensor(0.8281)),\n",
       "  (415, tensor(0.7656)),\n",
       "  (416, tensor(0.7500)),\n",
       "  (417, tensor(0.8281)),\n",
       "  (418, tensor(0.7500)),\n",
       "  (419, tensor(0.8438)),\n",
       "  (420, tensor(0.8125)),\n",
       "  (421, tensor(0.7500)),\n",
       "  (422, tensor(0.7344)),\n",
       "  (423, tensor(0.7812)),\n",
       "  (424, tensor(0.7188)),\n",
       "  (425, tensor(0.7344)),\n",
       "  (426, tensor(0.7812)),\n",
       "  (427, tensor(0.7969)),\n",
       "  (428, tensor(0.8281)),\n",
       "  (429, tensor(0.8438)),\n",
       "  (430, tensor(0.8594)),\n",
       "  (431, tensor(0.7344)),\n",
       "  (432, tensor(0.7969)),\n",
       "  (433, tensor(0.9062)),\n",
       "  (434, tensor(0.8438)),\n",
       "  (435, tensor(0.7031)),\n",
       "  (436, tensor(0.7344)),\n",
       "  (437, tensor(0.8438)),\n",
       "  (438, tensor(0.7969)),\n",
       "  (439, tensor(0.7656)),\n",
       "  (440, tensor(0.7812)),\n",
       "  (441, tensor(0.8594)),\n",
       "  (442, tensor(0.8594)),\n",
       "  (443, tensor(0.8438)),\n",
       "  (444, tensor(0.8125)),\n",
       "  (445, tensor(0.7656)),\n",
       "  (446, tensor(0.7969)),\n",
       "  (447, tensor(0.7812)),\n",
       "  (448, tensor(0.7500)),\n",
       "  (449, tensor(0.7812)),\n",
       "  (450, tensor(0.8125)),\n",
       "  (451, tensor(0.7344)),\n",
       "  (452, tensor(0.7969)),\n",
       "  (453, tensor(0.7969)),\n",
       "  (454, tensor(0.7812)),\n",
       "  (455, tensor(0.7344)),\n",
       "  (456, tensor(0.7812)),\n",
       "  (457, tensor(0.7812)),\n",
       "  (458, tensor(0.7344)),\n",
       "  (459, tensor(0.7656)),\n",
       "  (460, tensor(0.7656)),\n",
       "  (461, tensor(0.7812)),\n",
       "  (462, tensor(0.7500)),\n",
       "  (463, tensor(0.7188)),\n",
       "  (464, tensor(0.7188)),\n",
       "  (465, tensor(0.7812)),\n",
       "  (466, tensor(0.6719)),\n",
       "  (467, tensor(0.7188)),\n",
       "  (468, tensor(0.6875)),\n",
       "  (469, tensor(0.7656)),\n",
       "  (470, tensor(0.7188)),\n",
       "  (471, tensor(0.6875)),\n",
       "  (472, tensor(0.7812)),\n",
       "  (473, tensor(0.8281)),\n",
       "  (474, tensor(0.8438)),\n",
       "  (475, tensor(0.7344)),\n",
       "  (476, tensor(0.8125)),\n",
       "  (477, tensor(0.7656)),\n",
       "  (478, tensor(0.8594)),\n",
       "  (479, tensor(0.6875)),\n",
       "  (480, tensor(0.8281)),\n",
       "  (481, tensor(0.7969)),\n",
       "  (482, tensor(0.7656)),\n",
       "  (483, tensor(0.8125)),\n",
       "  (484, tensor(0.7969)),\n",
       "  (485, tensor(0.8125)),\n",
       "  (486, tensor(0.7344)),\n",
       "  (487, tensor(0.7969)),\n",
       "  (488, tensor(0.7812)),\n",
       "  (489, tensor(0.7969)),\n",
       "  (490, tensor(0.8594)),\n",
       "  (491, tensor(0.7969)),\n",
       "  (492, tensor(0.8281)),\n",
       "  (493, tensor(0.8125)),\n",
       "  (494, tensor(0.8594)),\n",
       "  (495, tensor(0.7344)),\n",
       "  (496, tensor(0.8125)),\n",
       "  (497, tensor(0.7344)),\n",
       "  (498, tensor(0.7344)),\n",
       "  (499, tensor(0.8594)),\n",
       "  (500, tensor(0.7188)),\n",
       "  (501, tensor(0.6562)),\n",
       "  (502, tensor(0.8125)),\n",
       "  (503, tensor(0.7500)),\n",
       "  (504, tensor(0.7656)),\n",
       "  (505, tensor(0.7188)),\n",
       "  (506, tensor(0.7344)),\n",
       "  (507, tensor(0.7969)),\n",
       "  (508, tensor(0.8125)),\n",
       "  (509, tensor(0.7812)),\n",
       "  (510, tensor(0.8125)),\n",
       "  (511, tensor(0.8281)),\n",
       "  (512, tensor(0.7969)),\n",
       "  (513, tensor(0.7031)),\n",
       "  (514, tensor(0.8281)),\n",
       "  (515, tensor(0.7969)),\n",
       "  (516, tensor(0.8125)),\n",
       "  (517, tensor(0.8125)),\n",
       "  (518, tensor(0.8281)),\n",
       "  (519, tensor(0.7500)),\n",
       "  (520, tensor(0.6875)),\n",
       "  (521, tensor(0.7969)),\n",
       "  (522, tensor(0.7656)),\n",
       "  (523, tensor(0.7031)),\n",
       "  (524, tensor(0.8125)),\n",
       "  (525, tensor(0.8594)),\n",
       "  (526, tensor(0.8906)),\n",
       "  (527, tensor(0.7969)),\n",
       "  (528, tensor(0.8281)),\n",
       "  (529, tensor(0.7188)),\n",
       "  (530, tensor(0.7188)),\n",
       "  (531, tensor(0.8281)),\n",
       "  (532, tensor(0.7969)),\n",
       "  (533, tensor(0.8750)),\n",
       "  (534, tensor(0.7500)),\n",
       "  (535, tensor(0.8125)),\n",
       "  (536, tensor(0.8125)),\n",
       "  (537, tensor(0.7656)),\n",
       "  (538, tensor(0.8281)),\n",
       "  (539, tensor(0.7031)),\n",
       "  (540, tensor(0.6875)),\n",
       "  (541, tensor(0.7500)),\n",
       "  (542, tensor(0.7500)),\n",
       "  (543, tensor(0.7031)),\n",
       "  (544, tensor(0.7969)),\n",
       "  (545, tensor(0.7344)),\n",
       "  (546, tensor(0.7969)),\n",
       "  (547, tensor(0.8438)),\n",
       "  (548, tensor(0.8750)),\n",
       "  (549, tensor(0.8906)),\n",
       "  (550, tensor(0.9062)),\n",
       "  (551, tensor(0.8750)),\n",
       "  (552, tensor(0.8281)),\n",
       "  (553, tensor(0.8438)),\n",
       "  (554, tensor(0.8594)),\n",
       "  (555, tensor(0.8906)),\n",
       "  (556, tensor(0.7812)),\n",
       "  (557, tensor(0.6719)),\n",
       "  (558, tensor(0.8438)),\n",
       "  (559, tensor(0.8594)),\n",
       "  (560, tensor(0.7812)),\n",
       "  (561, tensor(0.8750)),\n",
       "  (562, tensor(0.7812)),\n",
       "  (563, tensor(0.8750)),\n",
       "  (564, tensor(0.7812)),\n",
       "  (565, tensor(0.9062)),\n",
       "  (566, tensor(0.8906)),\n",
       "  (567, tensor(0.8906)),\n",
       "  (568, tensor(0.8594)),\n",
       "  (569, tensor(0.8906)),\n",
       "  (570, tensor(0.8750)),\n",
       "  (571, tensor(0.8438)),\n",
       "  (572, tensor(0.9219)),\n",
       "  (573, tensor(0.8906)),\n",
       "  (574, tensor(0.9219)),\n",
       "  (575, tensor(0.8281)),\n",
       "  (576, tensor(0.9062)),\n",
       "  (577, tensor(0.7812)),\n",
       "  (578, tensor(0.8906)),\n",
       "  (579, tensor(0.8594)),\n",
       "  (580, tensor(0.8594)),\n",
       "  (581, tensor(0.8594)),\n",
       "  (582, tensor(0.8281)),\n",
       "  (583, tensor(0.8125)),\n",
       "  (584, tensor(0.9219)),\n",
       "  (585, tensor(0.8438)),\n",
       "  (586, tensor(0.8594)),\n",
       "  (587, tensor(0.8594)),\n",
       "  (588, tensor(0.8125)),\n",
       "  (589, tensor(0.8438)),\n",
       "  (590, tensor(0.7812)),\n",
       "  (591, tensor(0.7656)),\n",
       "  (592, tensor(0.9062)),\n",
       "  (593, tensor(0.8594)),\n",
       "  (594, tensor(0.9062)),\n",
       "  (595, tensor(0.8438)),\n",
       "  (596, tensor(0.7812)),\n",
       "  (597, tensor(0.7812)),\n",
       "  (598, tensor(0.7812)),\n",
       "  (599, tensor(0.7969)),\n",
       "  (600, tensor(0.7188)),\n",
       "  (601, tensor(0.7812)),\n",
       "  (602, tensor(0.7344)),\n",
       "  (603, tensor(0.8438)),\n",
       "  (604, tensor(0.8125)),\n",
       "  (605, tensor(0.7969)),\n",
       "  (606, tensor(0.8438)),\n",
       "  (607, tensor(0.7969)),\n",
       "  (608, tensor(0.7812)),\n",
       "  (609, tensor(0.7969)),\n",
       "  (610, tensor(0.8750)),\n",
       "  (611, tensor(0.8594)),\n",
       "  (612, tensor(0.8594)),\n",
       "  (613, tensor(0.8750)),\n",
       "  (614, tensor(0.7969)),\n",
       "  (615, tensor(0.9062)),\n",
       "  (616, tensor(0.7969)),\n",
       "  (617, tensor(0.7812)),\n",
       "  (618, tensor(0.8438)),\n",
       "  (619, tensor(0.8438)),\n",
       "  (620, tensor(0.8906)),\n",
       "  (621, tensor(0.7812)),\n",
       "  (622, tensor(0.9375)),\n",
       "  (623, tensor(0.7969)),\n",
       "  (624, tensor(0.8750)),\n",
       "  (625, tensor(0.8906)),\n",
       "  (626, tensor(0.8281)),\n",
       "  (627, tensor(0.8594)),\n",
       "  (628, tensor(0.8594)),\n",
       "  (629, tensor(0.8594)),\n",
       "  (630, tensor(0.8906)),\n",
       "  (631, tensor(0.8125)),\n",
       "  (632, tensor(0.8750)),\n",
       "  (633, tensor(0.9062)),\n",
       "  (634, tensor(0.8438)),\n",
       "  (635, tensor(0.7812)),\n",
       "  (636, tensor(0.8594)),\n",
       "  (637, tensor(0.8125)),\n",
       "  (638, tensor(0.9062)),\n",
       "  (639, tensor(0.7969)),\n",
       "  (640, tensor(0.9062)),\n",
       "  (641, tensor(0.8281)),\n",
       "  (642, tensor(0.8438)),\n",
       "  (643, tensor(0.8125)),\n",
       "  (644, tensor(0.8750)),\n",
       "  (645, tensor(0.7969)),\n",
       "  (646, tensor(0.9219)),\n",
       "  (647, tensor(0.7188)),\n",
       "  (648, tensor(0.8906)),\n",
       "  (649, tensor(0.8906)),\n",
       "  (650, tensor(0.7969)),\n",
       "  (651, tensor(0.8438)),\n",
       "  (652, tensor(0.7812)),\n",
       "  (653, tensor(0.9062)),\n",
       "  (654, tensor(0.8750)),\n",
       "  (655, tensor(0.8125)),\n",
       "  (656, tensor(0.9375)),\n",
       "  (657, tensor(0.9062)),\n",
       "  (658, tensor(0.8750)),\n",
       "  (659, tensor(0.8281)),\n",
       "  (660, tensor(0.9375)),\n",
       "  (661, tensor(0.8281)),\n",
       "  (662, tensor(0.7969)),\n",
       "  (663, tensor(0.8594)),\n",
       "  (664, tensor(0.8125)),\n",
       "  (665, tensor(0.8281)),\n",
       "  (666, tensor(0.8594)),\n",
       "  (667, tensor(0.8438)),\n",
       "  (668, tensor(0.7812)),\n",
       "  (669, tensor(0.8125)),\n",
       "  (670, tensor(0.7969)),\n",
       "  (671, tensor(0.7188)),\n",
       "  (672, tensor(0.8750)),\n",
       "  (673, tensor(0.8906)),\n",
       "  (674, tensor(0.8906)),\n",
       "  (675, tensor(0.9219)),\n",
       "  (676, tensor(0.8750)),\n",
       "  (677, tensor(0.9062)),\n",
       "  (678, tensor(0.7812)),\n",
       "  (679, tensor(0.7812)),\n",
       "  (680, tensor(0.8594)),\n",
       "  (681, tensor(0.8750)),\n",
       "  (682, tensor(0.9219)),\n",
       "  (683, tensor(0.8438)),\n",
       "  (684, tensor(0.8594)),\n",
       "  (685, tensor(0.8125)),\n",
       "  (686, tensor(0.8906)),\n",
       "  (687, tensor(0.9062)),\n",
       "  (688, tensor(0.9219)),\n",
       "  (689, tensor(0.8594)),\n",
       "  (690, tensor(0.8906)),\n",
       "  (691, tensor(0.8438)),\n",
       "  (692, tensor(0.8281)),\n",
       "  (693, tensor(0.8594)),\n",
       "  (694, tensor(0.8906)),\n",
       "  (695, tensor(0.7969)),\n",
       "  (696, tensor(0.8750)),\n",
       "  (697, tensor(0.8438)),\n",
       "  (698, tensor(0.8594)),\n",
       "  (699, tensor(0.7969)),\n",
       "  (700, tensor(0.8125)),\n",
       "  (701, tensor(0.8906)),\n",
       "  (702, tensor(0.8906)),\n",
       "  (703, tensor(0.8750)),\n",
       "  (704, tensor(0.9375)),\n",
       "  (705, tensor(0.8281)),\n",
       "  (706, tensor(0.9375)),\n",
       "  (707, tensor(0.9531)),\n",
       "  (708, tensor(0.8594)),\n",
       "  (709, tensor(0.8750)),\n",
       "  (710, tensor(0.8594)),\n",
       "  (711, tensor(0.8438)),\n",
       "  (712, tensor(0.8594)),\n",
       "  (713, tensor(0.8281)),\n",
       "  (714, tensor(0.8906)),\n",
       "  (715, tensor(0.8594)),\n",
       "  (716, tensor(0.8906)),\n",
       "  (717, tensor(0.8906)),\n",
       "  (718, tensor(0.9062)),\n",
       "  (719, tensor(0.8750)),\n",
       "  (720, tensor(0.9062)),\n",
       "  (721, tensor(0.7344)),\n",
       "  (722, tensor(0.8750)),\n",
       "  (723, tensor(0.8750)),\n",
       "  (724, tensor(0.8750)),\n",
       "  (725, tensor(0.8906)),\n",
       "  (726, tensor(0.9375)),\n",
       "  (727, tensor(0.8750)),\n",
       "  (728, tensor(0.8438)),\n",
       "  (729, tensor(0.7812)),\n",
       "  (730, tensor(0.8281)),\n",
       "  (731, tensor(0.9062)),\n",
       "  (732, tensor(0.8281)),\n",
       "  (733, tensor(0.8594)),\n",
       "  (734, tensor(0.8906)),\n",
       "  (735, tensor(0.8906)),\n",
       "  (736, tensor(0.9219)),\n",
       "  (737, tensor(0.9062)),\n",
       "  (738, tensor(0.8125)),\n",
       "  (739, tensor(0.8906)),\n",
       "  (740, tensor(0.8125)),\n",
       "  (741, tensor(0.9219)),\n",
       "  (742, tensor(0.9219)),\n",
       "  (743, tensor(0.8438)),\n",
       "  (744, tensor(0.7500)),\n",
       "  (745, tensor(0.8750)),\n",
       "  (746, tensor(0.8438)),\n",
       "  (747, tensor(0.8750)),\n",
       "  (748, tensor(0.9062)),\n",
       "  (749, tensor(0.8906)),\n",
       "  (750, tensor(0.8438)),\n",
       "  (751, tensor(0.9219)),\n",
       "  (752, tensor(0.8281)),\n",
       "  (753, tensor(0.7656)),\n",
       "  (754, tensor(0.9062)),\n",
       "  (755, tensor(0.8906)),\n",
       "  (756, tensor(0.8125)),\n",
       "  (757, tensor(0.8750)),\n",
       "  (758, tensor(0.9062)),\n",
       "  (759, tensor(0.8750)),\n",
       "  (760, tensor(0.8750)),\n",
       "  (761, tensor(0.9531)),\n",
       "  (762, tensor(0.8125)),\n",
       "  (763, tensor(0.8281)),\n",
       "  (764, tensor(0.8906)),\n",
       "  (765, tensor(0.8750)),\n",
       "  (766, tensor(0.8906)),\n",
       "  (767, tensor(0.8750)),\n",
       "  (768, tensor(0.8594)),\n",
       "  (769, tensor(0.8906)),\n",
       "  (770, tensor(0.8594)),\n",
       "  (771, tensor(0.8750)),\n",
       "  (772, tensor(0.8125)),\n",
       "  (773, tensor(0.8906)),\n",
       "  (774, tensor(0.8906)),\n",
       "  (775, tensor(0.9219)),\n",
       "  (776, tensor(0.7812)),\n",
       "  (777, tensor(0.8594)),\n",
       "  (778, tensor(0.8125)),\n",
       "  (779, tensor(0.8281)),\n",
       "  (780, tensor(0.8750)),\n",
       "  (781, tensor(0.7969)),\n",
       "  (782, tensor(0.8594)),\n",
       "  (783, tensor(0.7969)),\n",
       "  (784, tensor(0.6875)),\n",
       "  (785, tensor(0.8750)),\n",
       "  (786, tensor(0.8906)),\n",
       "  (787, tensor(0.8594)),\n",
       "  (788, tensor(0.8438)),\n",
       "  (789, tensor(0.8906)),\n",
       "  (790, tensor(0.9219)),\n",
       "  (791, tensor(0.9062)),\n",
       "  (792, tensor(0.8906)),\n",
       "  (793, tensor(0.8750)),\n",
       "  (794, tensor(0.8906)),\n",
       "  (795, tensor(0.8906)),\n",
       "  (796, tensor(0.9219)),\n",
       "  (797, tensor(0.9531)),\n",
       "  (798, tensor(0.7969)),\n",
       "  (799, tensor(0.7812)),\n",
       "  (800, tensor(0.9062)),\n",
       "  (801, tensor(0.9688)),\n",
       "  (802, tensor(0.9219)),\n",
       "  (803, tensor(0.8594)),\n",
       "  (804, tensor(0.7812)),\n",
       "  (805, tensor(0.8906)),\n",
       "  (806, tensor(0.9062)),\n",
       "  (807, tensor(0.9219)),\n",
       "  (808, tensor(0.8750)),\n",
       "  (809, tensor(0.8594)),\n",
       "  (810, tensor(0.8906)),\n",
       "  (811, tensor(0.9219)),\n",
       "  (812, tensor(0.9375)),\n",
       "  (813, tensor(0.9375)),\n",
       "  (814, tensor(0.8125)),\n",
       "  (815, tensor(0.8438)),\n",
       "  (816, tensor(0.8906)),\n",
       "  (817, tensor(0.8750)),\n",
       "  (818, tensor(0.8750)),\n",
       "  (819, tensor(0.8594)),\n",
       "  (820, tensor(0.8750)),\n",
       "  (821, tensor(0.8750)),\n",
       "  (822, tensor(0.8750)),\n",
       "  (823, tensor(0.8438)),\n",
       "  (824, tensor(0.8125)),\n",
       "  (825, tensor(0.8906)),\n",
       "  (826, tensor(0.8281)),\n",
       "  (827, tensor(0.8750)),\n",
       "  (828, tensor(0.8750)),\n",
       "  (829, tensor(0.8750)),\n",
       "  (830, tensor(0.9375)),\n",
       "  (831, tensor(0.9219)),\n",
       "  (832, tensor(0.8125)),\n",
       "  (833, tensor(0.9219)),\n",
       "  (834, tensor(0.9375)),\n",
       "  (835, tensor(0.9062)),\n",
       "  (836, tensor(0.9062)),\n",
       "  (837, tensor(0.9219)),\n",
       "  (838, tensor(0.8906)),\n",
       "  (839, tensor(0.7969)),\n",
       "  (840, tensor(0.8281)),\n",
       "  (841, tensor(0.8125)),\n",
       "  (842, tensor(0.8281)),\n",
       "  (843, tensor(0.8125)),\n",
       "  (844, tensor(0.8750)),\n",
       "  (845, tensor(0.8906)),\n",
       "  (846, tensor(0.8906)),\n",
       "  (847, tensor(0.8750)),\n",
       "  (848, tensor(0.9375)),\n",
       "  (849, tensor(0.8750)),\n",
       "  (850, tensor(0.9219)),\n",
       "  (851, tensor(0.9062)),\n",
       "  (852, tensor(0.8906)),\n",
       "  (853, tensor(0.8438)),\n",
       "  (854, tensor(0.8438)),\n",
       "  (855, tensor(0.8281)),\n",
       "  (856, tensor(0.8906)),\n",
       "  (857, tensor(0.9062)),\n",
       "  (858, tensor(0.8906)),\n",
       "  (859, tensor(0.9062)),\n",
       "  (860, tensor(0.9062)),\n",
       "  (861, tensor(0.9062)),\n",
       "  (862, tensor(0.9219)),\n",
       "  (863, tensor(0.9531)),\n",
       "  (864, tensor(0.8438)),\n",
       "  (865, tensor(0.8438)),\n",
       "  (866, tensor(0.7969)),\n",
       "  (867, tensor(0.8906)),\n",
       "  (868, tensor(0.9375)),\n",
       "  (869, tensor(0.9062)),\n",
       "  (870, tensor(0.9062)),\n",
       "  (871, tensor(0.8750)),\n",
       "  (872, tensor(0.8438)),\n",
       "  (873, tensor(0.9062)),\n",
       "  (874, tensor(0.8750)),\n",
       "  (875, tensor(0.9375)),\n",
       "  (876, tensor(0.9062)),\n",
       "  (877, tensor(0.9219)),\n",
       "  (878, tensor(0.7969)),\n",
       "  (879, tensor(0.9219)),\n",
       "  (880, tensor(0.8750)),\n",
       "  (881, tensor(0.7812)),\n",
       "  (882, tensor(0.9219)),\n",
       "  (883, tensor(0.9062)),\n",
       "  (884, tensor(0.8906)),\n",
       "  (885, tensor(0.8594)),\n",
       "  (886, tensor(0.9219)),\n",
       "  (887, tensor(0.8438)),\n",
       "  (888, tensor(0.9062)),\n",
       "  (889, tensor(0.8750)),\n",
       "  (890, tensor(0.9375)),\n",
       "  (891, tensor(0.9062)),\n",
       "  (892, tensor(0.8750)),\n",
       "  (893, tensor(0.8438)),\n",
       "  (894, tensor(0.7969)),\n",
       "  (895, tensor(0.8594)),\n",
       "  (896, tensor(0.8438)),\n",
       "  (897, tensor(0.8594)),\n",
       "  (898, tensor(0.9219)),\n",
       "  (899, tensor(0.8438)),\n",
       "  (900, tensor(0.8750)),\n",
       "  (901, tensor(0.8906)),\n",
       "  (902, tensor(0.8125)),\n",
       "  (903, tensor(0.8594)),\n",
       "  (904, tensor(0.8125)),\n",
       "  (905, tensor(0.7812)),\n",
       "  (906, tensor(0.8750)),\n",
       "  (907, tensor(0.8438)),\n",
       "  (908, tensor(0.8594)),\n",
       "  (909, tensor(0.8438)),\n",
       "  (910, tensor(0.8438)),\n",
       "  (911, tensor(0.7344)),\n",
       "  (912, tensor(0.8594)),\n",
       "  (913, tensor(0.8750)),\n",
       "  (914, tensor(0.9219)),\n",
       "  (915, tensor(0.8438)),\n",
       "  (916, tensor(0.9062)),\n",
       "  (917, tensor(0.9062)),\n",
       "  (918, tensor(0.8125)),\n",
       "  (919, tensor(0.8438)),\n",
       "  (920, tensor(0.8906)),\n",
       "  (921, tensor(0.9531)),\n",
       "  (922, tensor(0.8906)),\n",
       "  (923, tensor(0.9062)),\n",
       "  (924, tensor(0.8594)),\n",
       "  (925, tensor(0.7812)),\n",
       "  (926, tensor(0.9062)),\n",
       "  (927, tensor(0.7500)),\n",
       "  (928, tensor(0.7969)),\n",
       "  (929, tensor(0.8281)),\n",
       "  (930, tensor(0.9062)),\n",
       "  (931, tensor(0.8594)),\n",
       "  (932, tensor(0.9062)),\n",
       "  (933, tensor(0.9688)),\n",
       "  (934, tensor(0.8125)),\n",
       "  (935, tensor(0.8594)),\n",
       "  (936, tensor(0.8906)),\n",
       "  (937, tensor(0.7812)),\n",
       "  (1095, tensor(0.9062)),\n",
       "  (1096, tensor(0.8438)),\n",
       "  (1097, tensor(0.7969)),\n",
       "  (1098, tensor(0.8438)),\n",
       "  (1099, tensor(0.9062)),\n",
       "  (1100, tensor(0.8281)),\n",
       "  (1101, tensor(0.8750)),\n",
       "  (1102, tensor(0.7344)),\n",
       "  (1103, tensor(0.8125)),\n",
       "  (1104, tensor(0.8125)),\n",
       "  (1105, tensor(0.9219)),\n",
       "  (1106, tensor(0.8906)),\n",
       "  (1107, tensor(0.7812)),\n",
       "  (1108, tensor(0.9531)),\n",
       "  (1109, tensor(0.9219)),\n",
       "  (1110, tensor(0.8594)),\n",
       "  (1111, tensor(0.8438)),\n",
       "  (1112, tensor(0.8906)),\n",
       "  (1113, tensor(0.7812)),\n",
       "  (1114, tensor(0.8281)),\n",
       "  (1115, tensor(0.8438)),\n",
       "  (1116, tensor(0.8438)),\n",
       "  (1117, tensor(0.8750)),\n",
       "  (1118, tensor(0.8594)),\n",
       "  (1119, tensor(0.9062)),\n",
       "  (1120, tensor(0.8750)),\n",
       "  (1121, tensor(0.8594)),\n",
       "  (1122, tensor(0.9062)),\n",
       "  (1123, tensor(0.8438)),\n",
       "  (1124, tensor(0.9531)),\n",
       "  (1125, tensor(0.8438)),\n",
       "  (1126, tensor(0.8125)),\n",
       "  (1127, tensor(0.8438)),\n",
       "  (1128, tensor(0.8438)),\n",
       "  (1129, tensor(0.8438)),\n",
       "  (1130, tensor(0.7969)),\n",
       "  (1131, tensor(0.8281)),\n",
       "  (1132, tensor(0.8281)),\n",
       "  (1133, tensor(0.8281)),\n",
       "  (1134, tensor(0.9219)),\n",
       "  (1135, tensor(0.8906)),\n",
       "  (1136, tensor(0.9062)),\n",
       "  (1137, tensor(0.9375)),\n",
       "  (1138, tensor(0.8906)),\n",
       "  (1139, tensor(0.8750)),\n",
       "  (1140, tensor(0.8750)),\n",
       "  (1141, tensor(0.8594)),\n",
       "  (1142, tensor(0.8594)),\n",
       "  (1143, tensor(0.8594)),\n",
       "  (1144, tensor(0.8750)),\n",
       "  (1145, tensor(0.8594)),\n",
       "  (1146, tensor(0.9375)),\n",
       "  (1147, tensor(0.8906)),\n",
       "  (1148, tensor(0.8281)),\n",
       "  (1149, tensor(0.9375)),\n",
       "  (1150, tensor(0.9062)),\n",
       "  (1151, tensor(0.9062)),\n",
       "  (1152, tensor(0.8750)),\n",
       "  (1153, tensor(0.8438)),\n",
       "  (1154, tensor(0.9062)),\n",
       "  (1155, tensor(0.8906)),\n",
       "  (1156, tensor(0.8750)),\n",
       "  ...],\n",
       " 'validation_loss': [(1095, 1.5478267669677734),\n",
       "  (2190, 1.4611504077911377),\n",
       "  (3285, 1.4763121604919434),\n",
       "  (4380, 1.4615378379821777),\n",
       "  (5475, 1.5236504077911377),\n",
       "  (6570, 1.4611504077911377),\n",
       "  (7665, 1.4611504077911377),\n",
       "  (8760, 1.4611504077911377),\n",
       "  (9855, 1.4611504077911377),\n",
       "  (10950, 1.5236504077911377)],\n",
       " 'validation_acc': [(1095, tensor(0.9375)),\n",
       "  (2190, tensor(1.)),\n",
       "  (3285, tensor(1.)),\n",
       "  (4380, tensor(1.)),\n",
       "  (5475, tensor(0.9375)),\n",
       "  (6570, tensor(1.)),\n",
       "  (7665, tensor(1.)),\n",
       "  (8760, tensor(1.)),\n",
       "  (9855, tensor(1.)),\n",
       "  (10950, tensor(0.9375))]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_training_loop(model, optimizer, train_loader, val_loader, scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bad71d-c223-48f1-9ab2-77506f7423b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
