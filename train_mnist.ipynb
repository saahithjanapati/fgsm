{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca049c7d-98c5-4deb-91f7-b0fb44d620b9",
   "metadata": {},
   "source": [
    "# Code to train an MNIST Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f997ee7-f5e2-468d-86e2-3abdbfe011b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchvision in /home/jax4zk/.local/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in /home/jax4zk/.local/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.5.1 (from torchvision)\n",
      "  Obtaining dependency information for torch==2.5.1 from https://files.pythonhosted.org/packages/d1/35/e8b2daf02ce933e4518e6f5682c72fd0ed66c15910ea1fb4168f442b71c4/torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jax4zk/.local/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->torchvision)\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==9.1.0.70 from https://files.pythonhosted.org/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.3.1.170)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->torchvision)\n",
      "  Obtaining dependency information for nvidia-nccl-cu12==2.21.5 from https://files.pythonhosted.org/packages/df/99/12cd266d6233f47d00daf3a72739872bdc10267d0383508b0b9c84a18bb6/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jax4zk/.local/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jax4zk/.local/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n",
      "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2, torchfrtrace and torchrun are installed in '/home/jax4zk/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ (/home/jax4zk/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lm-eval 0.4.7 requires zstandard, which is not installed.\n",
      "xformers 0.0.27.post2 requires torch==2.4.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cudnn-cu12 nvidia-nccl-cu12 torch\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60747653-2e11-4ea0-af2a-a1c4c7528990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c48b2b-0c85-409e-8f54-f78ea10b4c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8737fa-ee18-4439-b305-3093cb9de16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data', train=True, transform = transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfad523-84b4-4042-928c-3dbe213afa67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
    "val_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b2734c-0ba6-4cf6-a66d-babd5cdb0c84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "xtrain, ytrain = next(iter(train_loader))\n",
    "print(xtrain.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb4359-9639-4de2-8ccc-cdb5cf59ed54",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58b5c651-5506-45b1-8106-f6bc089d33d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123cb28f-5bc7-4107-b45a-55bd4e814972",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bddb1ae-b2e7-4679-99e5-2f36352e7393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MNISTClassifier()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 2, gamma=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d6665d-e427-4fee-822e-e90165e9566c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_num_correct(outputs, labels):\n",
    "    # outputs.shape: (b,10)\n",
    "    # labels.shape: (b)\n",
    "    max_output_vals, max_output_indices = outputs.max(dim=-1)\n",
    "    correct = torch.where(max_output_indices == labels, 1, 0)\n",
    "    \n",
    "    num_correct = torch.sum(correct, dim=-1)\n",
    "    total = correct.size(0)\n",
    "    return num_correct, total\n",
    "\n",
    "\n",
    "def run_training_loop(model, optimizer, train_loader, val_loader, scheduler, num_epochs=10, print_every=200):\n",
    "    device = next(model.parameters()).device # device that model is stored on\n",
    "    training_log = {\n",
    "        'training_loss': [],\n",
    "        'training_acc': [],\n",
    "        'validation_loss': [],\n",
    "        'validation_acc': []\n",
    "    }\n",
    "    \n",
    "    model.train()\n",
    "    num_iter = 0\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        for iter_idx, (xb,yb) in enumerate(train_loader):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            xb = xb.view(-1, 784)\n",
    "            out = model(xb) # b, 10\n",
    "            loss = F.cross_entropy(out, yb)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            num_correct, total = calculate_num_correct(out, yb)\n",
    "            \n",
    "            training_log['training_loss'].append((num_iter, loss.item()))\n",
    "            training_log['training_acc'].append((num_iter, num_correct / total))\n",
    "            \n",
    "            if num_iter % print_every == 0:\n",
    "                print(f'Epoch {i}, iter: {num_iter}: training loss: {training_log[\"training_loss\"][-1][1]}, training acc: {training_log[\"training_acc\"][-1][1]}')\n",
    "            \n",
    "            num_iter += 1\n",
    "        \n",
    "        \n",
    "        total_num_correct = 0\n",
    "        total_val_samples = 0\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # run evals\n",
    "        for iter_idx, (xb, yb) in enumerate(val_loader):\n",
    "            \n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            xb = xb.view(-1, 784)\n",
    "            out = model(xb)\n",
    "            loss = F.cross_entropy(out, yb)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "            \n",
    "            num_correct, total = calculate_num_correct(out, yb)\n",
    "            \n",
    "            total_num_correct += num_correct\n",
    "            total_val_samples += total\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            num_batches += 1\n",
    "\n",
    "            \n",
    "            \n",
    "        training_log['validation_loss'].append((num_iter, loss.item()))\n",
    "        training_log['validation_acc'].append((num_iter, num_correct / total))\n",
    "        \n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {i}, iter: {num_iter}: validation loss: {training_log[\"validation_loss\"][-1][1]}, validation acc: {training_log[\"validation_acc\"][-1][1]}')\n",
    "\n",
    "    \n",
    "    return training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1900fb66-97fb-462f-ba3c-5419770f2389",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter: 0: training loss: 2.3021204471588135, training acc: 0.046875\n",
      "Epoch 0, iter: 200: training loss: 0.26834169030189514, training acc: 0.890625\n",
      "Epoch 0, iter: 400: training loss: 0.3655937910079956, training acc: 0.90625\n",
      "Epoch 0, iter: 600: training loss: 0.12318333983421326, training acc: 0.96875\n",
      "Epoch 0, iter: 800: training loss: 0.3014961779117584, training acc: 0.921875\n",
      "Epoch 0, iter: 1095: validation loss: 0.11952541768550873, validation acc: 0.9375\n",
      "Epoch 1, iter: 1200: training loss: 0.22016116976737976, training acc: 0.90625\n",
      "Epoch 1, iter: 1400: training loss: 0.1932019293308258, training acc: 0.96875\n",
      "Epoch 1, iter: 1600: training loss: 0.11853666603565216, training acc: 0.953125\n",
      "Epoch 1, iter: 1800: training loss: 0.04204023629426956, training acc: 0.984375\n",
      "Epoch 1, iter: 2000: training loss: 0.06824303418397903, training acc: 0.984375\n",
      "Epoch 1, iter: 2190: validation loss: 0.015101161785423756, validation acc: 1.0\n",
      "Epoch 2, iter: 2200: training loss: 0.12811188399791718, training acc: 0.96875\n",
      "Epoch 2, iter: 2400: training loss: 0.0941242203116417, training acc: 0.96875\n",
      "Epoch 2, iter: 2600: training loss: 0.058999672532081604, training acc: 0.984375\n",
      "Epoch 2, iter: 2800: training loss: 0.18569234013557434, training acc: 0.953125\n",
      "Epoch 2, iter: 3000: training loss: 0.03874114900827408, training acc: 1.0\n",
      "Epoch 2, iter: 3285: validation loss: 0.0002732618886511773, validation acc: 1.0\n",
      "Epoch 3, iter: 3400: training loss: 0.014280770905315876, training acc: 1.0\n",
      "Epoch 3, iter: 3600: training loss: 0.12656156718730927, training acc: 0.96875\n",
      "Epoch 3, iter: 3800: training loss: 0.1249445229768753, training acc: 0.953125\n",
      "Epoch 3, iter: 4000: training loss: 0.0789741724729538, training acc: 0.984375\n",
      "Epoch 3, iter: 4200: training loss: 0.05790316313505173, training acc: 0.96875\n",
      "Epoch 3, iter: 4380: validation loss: 0.0006115009309723973, validation acc: 1.0\n",
      "Epoch 4, iter: 4400: training loss: 0.09291349351406097, training acc: 0.96875\n",
      "Epoch 4, iter: 4600: training loss: 0.03305288776755333, training acc: 0.984375\n",
      "Epoch 4, iter: 4800: training loss: 0.10564212501049042, training acc: 0.953125\n",
      "Epoch 4, iter: 5000: training loss: 0.05198933556675911, training acc: 0.984375\n",
      "Epoch 4, iter: 5200: training loss: 0.04014495760202408, training acc: 0.984375\n",
      "Epoch 4, iter: 5475: validation loss: 4.197871749056503e-05, validation acc: 1.0\n",
      "Epoch 5, iter: 5600: training loss: 0.02216298133134842, training acc: 0.984375\n",
      "Epoch 5, iter: 5800: training loss: 0.0965205654501915, training acc: 0.96875\n",
      "Epoch 5, iter: 6000: training loss: 0.03886653482913971, training acc: 0.984375\n",
      "Epoch 5, iter: 6200: training loss: 0.006464947015047073, training acc: 1.0\n",
      "Epoch 5, iter: 6400: training loss: 0.05303522199392319, training acc: 0.984375\n",
      "Epoch 5, iter: 6570: validation loss: 1.5600699043716304e-05, validation acc: 1.0\n",
      "Epoch 6, iter: 6600: training loss: 0.060672860592603683, training acc: 0.984375\n",
      "Epoch 6, iter: 6800: training loss: 0.014533230103552341, training acc: 1.0\n",
      "Epoch 6, iter: 7000: training loss: 0.051364172250032425, training acc: 0.984375\n",
      "Epoch 6, iter: 7200: training loss: 0.05087204650044441, training acc: 0.96875\n",
      "Epoch 6, iter: 7400: training loss: 0.05769239366054535, training acc: 0.984375\n",
      "Epoch 6, iter: 7665: validation loss: 1.8126109353033826e-05, validation acc: 1.0\n",
      "Epoch 7, iter: 7800: training loss: 0.09742781519889832, training acc: 0.953125\n",
      "Epoch 7, iter: 8000: training loss: 0.10130388289690018, training acc: 0.96875\n",
      "Epoch 7, iter: 8200: training loss: 0.10232120007276535, training acc: 0.96875\n",
      "Epoch 7, iter: 8400: training loss: 0.051173679530620575, training acc: 0.984375\n",
      "Epoch 7, iter: 8600: training loss: 0.05032126605510712, training acc: 0.984375\n",
      "Epoch 7, iter: 8760: validation loss: 1.8998914583789883e-06, validation acc: 1.0\n",
      "Epoch 8, iter: 8800: training loss: 0.003495215903967619, training acc: 1.0\n",
      "Epoch 8, iter: 9000: training loss: 0.04737767577171326, training acc: 0.984375\n",
      "Epoch 8, iter: 9200: training loss: 0.055209606885910034, training acc: 0.984375\n",
      "Epoch 8, iter: 9400: training loss: 0.005661755334585905, training acc: 1.0\n",
      "Epoch 8, iter: 9600: training loss: 0.017072448506951332, training acc: 1.0\n",
      "Epoch 8, iter: 9855: validation loss: 4.6416612349275965e-06, validation acc: 1.0\n",
      "Epoch 9, iter: 10000: training loss: 0.006396890617907047, training acc: 1.0\n",
      "Epoch 9, iter: 10200: training loss: 0.0040221563540399075, training acc: 1.0\n",
      "Epoch 9, iter: 10400: training loss: 0.026689698919653893, training acc: 0.984375\n",
      "Epoch 9, iter: 10600: training loss: 0.04394257441163063, training acc: 0.984375\n",
      "Epoch 9, iter: 10950: validation loss: 9.238694929081248e-07, validation acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "training_log = run_training_loop(model, optimizer, train_loader, val_loader, scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02bad71d-c223-48f1-9ab2-77506f7423b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a167cb1-0827-492f-a344-3aeb89e86efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
